{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed828836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages in PDF: 71\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 1 ---\n",
      "\n",
      "FP25-119-D-Rehnuma\n",
      "Project Team\n",
      "Faseeh Iqbal 22I-1856\n",
      "Ahmad Hasan 22I-1945\n",
      "Manhab Zafar 22I-1957\n",
      "Session 2022-2026\n",
      "Supervised by\n",
      "Ms. Amna Irum\n",
      "Co-Supervised by\n",
      "Dr. Qurut-ul-Ain\n",
      "Department of Data Science And Artificial Intelligence\n",
      "National University of Computer and Emerging Sciences\n",
      "Islamabad, Pakistan\n",
      "June, 2026\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 2 ---\n",
      "\n",
      "Contents\n",
      "1 Introduction 11\n",
      "1.1 Existing Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n",
      "1.2 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n",
      "1.3 Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n",
      "1.4 Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n",
      "1.4.1 Module 1: Dataset Pipeline . . . . . . . . . . . . . . . . . . . . 33\n",
      "1.4.2 Module 2: Animation Pipeline . . . . . . . . . . . . . . . . . . . 44\n",
      "1.4.3 Module 3: Quiz System . . . . . . . . . . . . . . . . . . . . . . . 44\n",
      "1.4.4 Module 4: Real-Time QA System . . . . . . . . . . . . . . . . . 44\n",
      "1.4.5 Module 5: Personalized Dashboard . . . . . . . . . . . . . . . . . 44\n",
      "1.4.6 Module 6: Classroom . . . . . . . . . . . . . . . . . . . . . . . 55\n",
      "2 Project Requirements 77\n",
      "2.1 Use-case/Event Response Table/Storyboarding . . . . . . . . . . . . . . . 77\n",
      "2.2 Functional Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n",
      "2.2.1 Module 1: Dataset Pipeline . . . . . . . . . . . . . . . . . . . . . 77\n",
      "2.2.2 Module 2: Animation Pipeline . . . . . . . . . . . . . . . . . . . 88\n",
      "2.2.3 Module 3: Quiz System . . . . . . . . . . . . . . . . . . . . . . . 99\n",
      "2.2.4 Module 4: Real-Time QA System . . . . . . . . . . . . . . . . . 1010\n",
      "2.2.5 Module 5: Personalized Dashboard . . . . . . . . . . . . . . . . . 1010\n",
      "2.2.6 Module 6: Classroom . . . . . . . . . . . . . . . . . . . . . . . . 1111\n",
      "2.3 Non-Functional Requirements . . . . . . . . . . . . . . . . . . . . . . . 1111\n",
      "2.3.1 Reliability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1111\n",
      "2.3.2 Usability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1212\n",
      "2.3.3 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1313\n",
      "2.3.4 Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1313\n",
      "3 System Overview 1515\n",
      "3.1 Architectural Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1515\n",
      "3.2 Data Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1717\n",
      "3.3 Domain Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1919\n",
      "3.4 Design Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2323\n",
      "3.4.1 Behavioral and Structural Diagrams . . . . . . . . . . . . . . . . 2323\n",
      "2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 3 ---\n",
      "\n",
      "CONTENTS\n",
      "3.4.1.1 Activity Diagram . . . . . . . . . . . . . . . . . . . . . 2323\n",
      "3.4.1.2 Class Diagram . . . . . . . . . . . . . . . . . . . . . . 2525\n",
      "3.4.1.3 Sequence Diagram . . . . . . . . . . . . . . . . . . . . 2727\n",
      "3.4.1.4 DataFlow Diagram . . . . . . . . . . . . . . . . . . . . 3030\n",
      "4 Implementation and Testing 3333\n",
      "4.1 Algorithm Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3333\n",
      "4.1.1 Vector Similarity Search Algorithm . . . . . . . . . . . . . . . . 3434\n",
      "4.1.2 Dataset Generation Algorithm . . . . . . . . . . . . . . . . . . . 3434\n",
      "4.1.3 Quiz Generation Algorithm . . . . . . . . . . . . . . . . . . . . . 3535\n",
      "4.2 External APIs/SDKs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3535\n",
      "4.2.1 Groq API Integration Details . . . . . . . . . . . . . . . . . . . . 3737\n",
      "4.3 Testing Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3939\n",
      "4.3.1 Unit Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3939\n",
      "4.3.1.1 Test Case 1: Query Validation . . . . . . . . . . . . . . 3939\n",
      "4.3.1.2 Test Case 2: Vector Similarity Search . . . . . . . . . . 4141\n",
      "4.3.1.3 Test Case 3: Manim Code Validation . . . . . . . . . . 4343\n",
      "4.3.1.4 Test Case 4: Solution Validation with SymPy . . . . . . 4545\n",
      "4.3.2 Integration Testing . . . . . . . . . . . . . . . . . . . . . . . . . 4747\n",
      "4.3.2.1 End-to-End Animation Generation Test . . . . . . . . . 4747\n",
      "4.3.2.2 Quiz Generation and Submission Flow Test . . . . . . . 4848\n",
      "4.3.3 Performance Testing . . . . . . . . . . . . . . . . . . . . . . . . 5050\n",
      "4.3.3.1 Load Testing Results . . . . . . . . . . . . . . . . . . . 5050\n",
      "4.3.3.2 Stress Testing . . . . . . . . . . . . . . . . . . . . . . . 5151\n",
      "4.3.4 Security Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . 5353\n",
      "4.3.4.1 SQL Injection Testing . . . . . . . . . . . . . . . . . . 5353\n",
      "4.3.4.2 API Key Security Testing . . . . . . . . . . . . . . . . 5454\n",
      "4.3.5 Known Issues and Limitations . . . . . . . . . . . . . . . . . . . 5454\n",
      "A Appendices 5555\n",
      "A.1 Appendix A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5656\n",
      "A.1.1 Use Case Diagram example (Rehnuma) . . . . . . . . . . . . . . 5656\n",
      "A.1.2 Detail Use Case Example . . . . . . . . . . . . . . . . . . . . . . 5757\n",
      "A.2 Appendix B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5959\n",
      "A.2.1 Class Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . 5959\n",
      "A.3 Appendix C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6060\n",
      "A.3.1 Architecture Pattern Example . . . . . . . . . . . . . . . . . . . . 6060\n",
      "A.4 Appendix D . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6262\n",
      "A.4.1 Activity Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . 6262\n",
      "A.4.2 Sequence Diagram . . . . . . . . . . . . . . . . . . . . . . . . . 6363\n",
      "A.4.3 Data Flow Diagram . . . . . . . . . . . . . . . . . . . . . . . . . 6565\n",
      "3\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 4 ---\n",
      "\n",
      "List of Figures\n",
      "3.1 Architecture Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1717\n",
      "3.2 Usecase Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2222\n",
      "3.3 Activity Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2424\n",
      "3.4 Class Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2626\n",
      "3.5 Sequence Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2929\n",
      "3.6 DataFlow Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3232\n",
      "4.1 Dashboard . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3939\n",
      "4.2 Dashboard-2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4040\n",
      "4.3 Solution-Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4141\n",
      "4.4 Manim-Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4545\n",
      "4.5 Animation-Calculation . . . . . . . . . . . . . . . . . . . . . . . . . . . 5050\n",
      "4.6 Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5151\n",
      "4.7 Testcases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5353\n",
      "A.1 Use Case Diagram for Rehnuma . . . . . . . . . . . . . . . . . . . . . . 5656\n",
      "A.2 Detailed Use Case Example of Rehnuma . . . . . . . . . . . . . . . . . . 5858\n",
      "A.3 Class Diagram for Rehnuma . . . . . . . . . . . . . . . . . . . . . . . . 5959\n",
      "A.4 Architecture Pattern For Rehnuma . . . . . . . . . . . . . . . . . . . . . 6060\n",
      "A.5 Activity Diagram For Rehnuma . . . . . . . . . . . . . . . . . . . . . . . 6262\n",
      "A.6 Sequence Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6464\n",
      "A.7 Data Flow Diagram for Rehnuma . . . . . . . . . . . . . . . . . . . . . . 6666\n",
      "4\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 5 ---\n",
      "\n",
      "List of Tables\n",
      "1.1 Comparison of Existing Solutions . . . . . . . . . . . . . . . . . . . . . 22\n",
      "4.1 External APIs and SDKs Used in Rehnuma . . . . . . . . . . . . . . . . 3636\n",
      "4.2 Performance Testing Results . . . . . . . . . . . . . . . . . . . . . . . . 5151\n",
      "0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 6 ---\n",
      "\n",
      "Chapter 1\n",
      "Introduction\n",
      "The purpose of this project proposal is to present “Rehnuma”, an intelligent animated\n",
      "tutoring system designed to assist students in understanding advanced statistical concepts\n",
      "with greater clarity and efficiency. In the current educational environment, students of-\n",
      "ten face significant challenges when dealing with probability and statistics, particularly\n",
      "during their initial semesters where prior exposure is limited. Traditional learning re-\n",
      "sources such as static notes, lengthy textbooks, or unstructured online videos often fail to\n",
      "provide personalized and interactive explanations. Rehnuma bridges this gap by offering\n",
      "a system that dynamically generates animated videos, coupled with explanatory narra-\n",
      "tion, tailored to specific queries raised by students. By integrating large language models\n",
      "(LLMs), retrieval-augmented generation (RAG) pipelines, and Manim animations, the\n",
      "system ensures that learners receive accurate, visual, and concept-based explanations.\n",
      "This approach not only makes abstract concepts easier to grasp but also enhances long-\n",
      "term retention. The proposed system will ultimately create a self-adaptive, accessible,\n",
      "and interactive platform that aligns with modern digital learning trends.?.\n",
      "1.1 Existing Solutions\n",
      "Several online learning platforms currently provide mathematics and science education,\n",
      "but they present notable limitations in personalization and real-time interaction. The two\n",
      "leading solutions are:\n",
      "•Khan Academy\n",
      "Offers a large library of pre-recorded video lessons with clear narration, structured\n",
      "topic progression, practice exercises, and limited quiz integration.\n",
      "1\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 7 ---\n",
      "\n",
      "1. Introduction\n",
      "•Brilliant.org\n",
      "Provides pre-designed interactive lessons, rich quiz integration, problem-solving-\n",
      "focused courses, and supporting text/narration. Personalization is restricted to pre-\n",
      "defined course paths.\n",
      "Table 1.1: Comparison of Existing Solutions\n",
      "System Name System Overview System Limitations\n",
      "Khan Academy\n",
      "• Pre-recorded video expla-\n",
      "nations with narration\n",
      "• Structured courses and\n",
      "practice exercises\n",
      "• Limited quiz integration• No personalization\n",
      "• No support for user-input\n",
      "queries\n",
      "• No real-time Q&A\n",
      "• Pre-recorded content only\n",
      "Brilliant.org\n",
      "• Pre-designed interactive\n",
      "explanations\n",
      "• Strong quiz integration\n",
      "• Structured, problem-\n",
      "solving-focused courses\n",
      "• Narration/supporting text• Limited personalization\n",
      "(only within predefined\n",
      "courses)\n",
      "• No support for arbitrary\n",
      "user-input queries\n",
      "• No real-time Q&A\n",
      "1.2 Problem Statement\n",
      "Students entering advanced courses in probability and statistics frequently encounter dif-\n",
      "ficulties due to their limited background in conceptual mathematics. These difficulties of-\n",
      "ten lead to surface-level understanding and a lack of problem-solving confidence. While\n",
      "numerous online resources such as YouTube lectures and digital textbooks exist, they re-\n",
      "quire students to spend a considerable amount of time searching for the right content,\n",
      "which is often not aligned with their exact query. Moreover, most of these resources\n",
      "present content in a generic, onesize-fits-all manner that does not adapt to a learner’s spe-\n",
      "cific knowledge gaps. This inefficiency reduces the effectiveness of independent learning,\n",
      "especially for students who require instant clarity. Students may also face cognitive over-\n",
      "load while navigating long lectures for a single concept. The absence of interactive and\n",
      "context-aware tutoring tools contributes to weak conceptual foundations, resulting in poor\n",
      "2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 8 ---\n",
      "\n",
      "1.3 Scope\n",
      "academic performance. Rehnuma addresses this problem by providing an on-demand in-\n",
      "telligent tutor capable of delivering personalized animated explanations directly based on\n",
      "student queries. By doing so, the system eliminates the inefficiencies of manual content\n",
      "search and ensures that students receive focused, visual, and clear explanations.\n",
      "1.3 Scope\n",
      "The scope of Rehnuma encompasses the development of a fully functional prototype that\n",
      "demonstrates the generation of animated explanations for queries. The main focus lies in\n",
      "probability and statistics concepts, ensuring that the content generated is accurate, rele-\n",
      "vant, and comprehensible. The system will include functionalities such as query-based\n",
      "animated video generation, quiz generation, real-time QA, personalized dashboard, and\n",
      "a classroom. Scope boundaries include limiting the dataset to curated problems from se-\n",
      "lected textbooks and restricting animation generation to Manim-compatible scripts. The\n",
      "solution will not attempt to replace human instruction but rather supplement it by pro-\n",
      "viding students with an intelligent self-learning platform. This ensures a clear boundary\n",
      "between automated explanations and human-led discussions, making the system a sup-\n",
      "portive tool rather than a replacement. The system will demonstrate the feasibility of\n",
      "integrating LLMs, RAG pipelines, and Manim to create an adaptive educational tool that\n",
      "enhances independent learning, improves conceptual clarity, and promotes confidence in\n",
      "tackling mathematical problems.\n",
      "1.4 Modules\n",
      "1.4.1 Module 1: Dataset Pipeline\n",
      "This module is responsible for creating and managing the core dataset required for query-\n",
      "based explanations. It ensures structured storage of problems, solutions, and animation\n",
      "codes in a retrievable format for efficient usage in the system.\n",
      "1. Generate a dataset using DeepSeek Math from textbook solutions.\n",
      "2. Store problems with multiple keys (description, code, etc.) in JSON format.\n",
      "3. Implement ChromaDB for vector storage and retrieval\n",
      "3\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 9 ---\n",
      "\n",
      "1. Introduction\n",
      "1.4.2 Module 2: Animation Pipeline\n",
      "The animation pipeline generates customized visual explanations based on student queries.\n",
      "It integrates solution generation, reference retrieval, and code rendering to create synchro-\n",
      "nized video and audio explanations.\n",
      "1. Use DeepSeek Math for solution generation.\n",
      "2. Retrieve reference problems through RAG.\n",
      "3. Employ DeepSeek Code for generating Manim-compatible code.\n",
      "4. Render animations with synced audio explanations using gtts (Python library).\n",
      "1.4.3 Module 3: Quiz System\n",
      "This module reinforces learning by generating quizzes linked to student queries. It allows\n",
      "students to test their understanding and track progress through structured evaluations.\n",
      "1. Generate quizzes from user queries using DeepSeek Math.\n",
      "2. Provide multiple-choice questions (MCQs) with scoring.\n",
      "3. Integrate with the dashboard for progress tracking.\n",
      "1.4.4 Module 4: Real-Time QA System\n",
      "The QA system enables instant responses to student doubts during or after lessons. It\n",
      "ensures continuity in the learning process through text-based, real-time interaction.\n",
      "1. Use DeepSeek Math for real-time responses.\n",
      "2. Provide answers in text format.\n",
      "1.4.5 Module 5: Personalized Dashboard\n",
      "This module offers personalized tracking of a student’s progress and performance. It\n",
      "ensures learners receive feedback and insights into their strengths and weaknesses.\n",
      "1. Display quiz history and performance analytics.\n",
      "2. Maintain personalized progress records.\n",
      "3. Provide visual feedback to learners.\n",
      "4\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 10 ---\n",
      "\n",
      "1.4 Modules\n",
      "1.4.6 Module 6: Classroom\n",
      "The classroom module supports collaborative learning by enabling group-based participa-\n",
      "tion. It allows users to share learning experiences and benefit from interactive discussions.\n",
      "1. Develop a classroom for collaboration.\n",
      "2. Users will be able to invite other users and watch animations together.\n",
      "5\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 11 ---\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 12 ---\n",
      "\n",
      "Chapter 2\n",
      "Project Requirements\n",
      "2.1 Use-case/Event Response Table/Storyboarding\n",
      "Since Rehnuma is an interactive end-user application, the use case approach is most suit-\n",
      "able. The system involves multiple user interactions across different modules, making use\n",
      "case diagrams and detailed use cases the ideal requirement gathering technique.\n",
      "1. Generate Animated Explanation\n",
      "2. Take Quiz\n",
      "3. Ask Real-Time Question\n",
      "4. View Progress Dashboard\n",
      "5. Join Classroom Session\n",
      "6. Create Dataset Entry (Admin)\n",
      "2.2 Functional Requirements\n",
      "2.2.1 Module 1: Dataset Pipeline\n",
      "Following are the requirements for module 1:\n",
      "FR1.1:Dataset GenerationThe system shall allow administrators to input textbook prob-\n",
      "lems and solutions, which will be processed by DeepSeek Math to generate structured\n",
      "dataset entries containing problem descriptions, solutions, and metadata.\n",
      "7\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 13 ---\n",
      "\n",
      "2. Project Requirements\n",
      "FR1.2 Code Generation and ValidationThe system shall use DeepSeek Math to gen-\n",
      "erate Python code from problem-solution pairs and validate the generated code using\n",
      "SymPy and NumPy libraries before storage.\n",
      "FR1.3 Manim Code GenerationThe system shall automatically generate Manim-compatible\n",
      "animation code and associated metadata for each validated problem-solution pair using\n",
      "Code-Llama.\n",
      "FR1.4 JSON StorageThe system shall store all dataset entries in JSON format with\n",
      "multiple searchable keys including problem description, solution steps, Manim code, dif-\n",
      "ficulty level, topic tags, and unique identifiers.\n",
      "FR1.5 Vector Database IntegrationThe system shall implement ChromaDB for vec-\n",
      "tor storage, enabling semantic search and efficient retrieval of similar problems based on\n",
      "query embeddings.\n",
      "FR1.6 Dataset VersioningThe system shall maintain version control for dataset entries,\n",
      "allowing administrators to update, modify, or deprecate entries while preserving historical\n",
      "data.\n",
      "2.2.2 Module 2: Animation Pipeline\n",
      "Following are the requirements for module 2:\n",
      "FR2.1 Query ProcessingThe system shall accept natural language queries from students\n",
      "and process them through prompt engineering to enhance retrieval accuracy.\n",
      "FR2.2 RAG-based RetrievalThe system shall retrieve the top-k most relevant reference\n",
      "problems from ChromaDB based on semantic similarity to the user’s query.\n",
      "FR2.3 Solution GenerationThe system shall generate step-by-step mathematical solu-\n",
      "tions using DeepSeek Math, incorporating context from retrieved reference problems to\n",
      "ensure accuracy and relevance.\n",
      "FR2.4 Animation Code GenerationThe system shall use Code-Llama to convert the\n",
      "generated solution into Manim-compatible Python code that visualizes the problem-solving\n",
      "8\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 14 ---\n",
      "\n",
      "2.2 Functional Requirements\n",
      "process.\n",
      "FR2.5 Video RenderingThe system shall render the Manim code into high-quality ani-\n",
      "mated videos (720p minimum) showing step-by-step visualization of the solution.\n",
      "FR2.6 Audio NarrationThe system shall generate synchronized audio explanations us-\n",
      "ing Google Text-to-Speech (gtts) library, providing clear narration of each solution step\n",
      "alongside the visual animation.\n",
      "FR2.7 Output DeliveryThe system shall deliver the final animated explanation to the\n",
      "user within 60 seconds of query submission, displaying both video and synchronized\n",
      "audio.\n",
      "2.2.3 Module 3: Quiz System\n",
      "Following are the requirements for module 3:\n",
      "FR3.1 Quiz GenerationThe system shall generate topic-specific quizzes based on user\n",
      "queries or selected topics using DeepSeek Math, with 5–10 multiple-choice questions per\n",
      "quiz.\n",
      "FR3.2 Question Difficulty LevelsThe system shall categorize quiz questions into three\n",
      "difficulty levels: beginner, intermediate, and advanced, allowing students to select appro-\n",
      "priate challenges.\n",
      "FR3.3 Answer ValidationThe system shall automatically validate student responses,\n",
      "provide immediate feedback, and calculate scores based on correct answers.\n",
      "FR3.4 Detailed SolutionsThe system shall provide detailed explanations for each quiz\n",
      "question after submission, helping students understand their mistakes.\n",
      "FR3.5 Quiz HistoryThe system shall maintain a complete history of all quizzes at-\n",
      "tempted by each student, including timestamps, scores, and topics covered.\n",
      "9\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 15 ---\n",
      "\n",
      "2. Project Requirements\n",
      "2.2.4 Module 4: Real-Time QA System\n",
      "Following are the requirements for module 4:\n",
      "FR4.1 Text-based Query HandlingThe system shall accept text-based questions from\n",
      "students and provide instant responses using DeepSeek Math without generating anima-\n",
      "tions.\n",
      "FR4.2 Contextual ResponsesThe system shall maintain conversation context, allowing\n",
      "follow-up questions and clarifications within the same session.\n",
      "FR4.3 Response TimeThe system shall provide text-based answers within 5 seconds of\n",
      "query submission for optimal user experience.\n",
      "FR4.4 Query HistoryThe system shall store all QA interactions for each student, en-\n",
      "abling review of previous questions and answers.\n",
      "2.2.5 Module 5: Personalized Dashboard\n",
      "Following are the requirements for module 5:\n",
      "FR5.1 Performance AnalyticsThe system shall display comprehensive analytics includ-\n",
      "ing quiz scores, topics covered, time spent, and improvement trends using visual charts\n",
      "and graphs.\n",
      "FR5.2 Progress TrackingThe system shall track and display the student’s learning jour-\n",
      "ney, showing completed topics, pending areas, and recommended next steps.\n",
      "FR5.3 Strengths and Weaknesses AnalysisThe system shall analyze quiz performance\n",
      "to identify student strengths and weaknesses in different probability and statistics topics.\n",
      "FR5.4 Learning RecommendationsThe system shall provide personalized topic recom-\n",
      "mendations based on past performance and identified knowledge gaps.\n",
      "FR5.5 Goal SettingThe system shall allow students to set learning goals and track\n",
      "progress toward achieving them.\n",
      "10\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 16 ---\n",
      "\n",
      "2.3 Non-Functional Requirements\n",
      "2.2.6 Module 6: Classroom\n",
      "Following are the requirements for module 6:\n",
      "FR6.1 Classroom CreationThe system shall allow users to create virtual classrooms\n",
      "with unique codes for collaborative learning sessions.\n",
      "FR6.2 User InvitationThe system shall enable classroom creators to invite other users\n",
      "via unique classroom codes or direct links.\n",
      "FR6.3 Synchronized ViewingThe system shall provide synchronized animation play-\n",
      "back, allowing all classroom participants to watch explanations simultaneously.\n",
      "FR6.4 Real-time ChatThe system shall include a text-based chat feature enabling stu-\n",
      "dents to discuss concepts during classroom sessions.\n",
      "FR6.5 Session RecordingThe system shall optionally record classroom sessions for later\n",
      "review by participants.\n",
      "2.3 Non-Functional Requirements\n",
      "2.3.1 Reliability\n",
      "Following are the reliability requirements:\n",
      "REL-1: System UptimeThe system shall maintain 80-83% uptime during academic\n",
      "semesters with planned maintenance.\n",
      "REL-2: Failure RecoveryIn case of animation generation failure, the system shall auto-\n",
      "matically retry within minutes before notifying the user and logging the error for admin-\n",
      "istrator review.\n",
      "11\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 17 ---\n",
      "\n",
      "2. Project Requirements\n",
      "REL-3: Data IntegrityThe system shall implement automatic database backups every\n",
      "24 hours and maintain backup copies for at least 30 days to ensure data recovery in case\n",
      "of failures.\n",
      "REL-4: Error HandlingThe system shall gracefully handle API failures from DeepSeek\n",
      "by displaying user-friendly error messages and suggesting alternative actions (e.g., try\n",
      "simpler query, use QA system instead).\n",
      "2.3.2 Usability\n",
      "Following are the usability requirements:\n",
      "USE-1: Learning CurveNew users shall be able to generate their first animated expla-\n",
      "nation within minutes of account creation, with minimal training or documentation.\n",
      "USE-2: Query SimplicityUsers shall be able to submit queries using natural language\n",
      "without requiring specific formatting or technical syntax.\n",
      "USE-3: Interface ClarityThe system shall use intuitive icons, clear labels, and consis-\n",
      "tent navigation patterns across all modules to minimize cognitive load.\n",
      "USE-4: Error RecoveryIf a user submits an unclear or ambiguous query, the system\n",
      "shall provide suggestions for query refinement rather than simply returning an error.\n",
      "USE-5: AccessibilityThe system shall support screen readers and keyboard navigation,\n",
      "ensuring accessibility for users with visual or motor impairments.\n",
      "USE-6: Mobile ResponsivenessThe web interface shall be fully responsive, providing\n",
      "optimal viewing experience across desktop, tablet, and mobile devices.\n",
      "USE-7: One-Click AccessUsers shall be able to access their quiz history and dashboard\n",
      "with a single click from any page within the system.\n",
      "12\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 18 ---\n",
      "\n",
      "2.3 Non-Functional Requirements\n",
      "2.3.3 Performance\n",
      "Following are the performance requirements:\n",
      "PER-1: Animation Generation Time95% of animation requests shall be completed\n",
      "within minutes from query submission to video delivery, including solution generation,\n",
      "code creation, and rendering.\n",
      "PER-2: Real-Time QA ResponseText-based QA responses shall be delivered within\n",
      "minutes for 99% of queries.\n",
      "PER-3: Quiz Loading TimeQuiz pages shall load completely within minutes on stan-\n",
      "dard broadband connections (10 Mbps or higher).\n",
      "PER-4: Concurrent UsersThe system shall support at least 50 concurrent users gener-\n",
      "ating animations simultaneously without performance degradation.\n",
      "PER-5: Database Query PerformanceVector similarity searches in ChromaDB shall\n",
      "return results within 1-2 seconds for 95% of queries.\n",
      "PER-6: Video StreamingRendered animations shall begin playback within 3 seconds of\n",
      "user request with smooth streaming at 720p resolution.\n",
      "PER-7: Dashboard LoadingPersonalized dashboard shall load all analytics and visual-\n",
      "izations within minutes.\n",
      "2.3.4 Security\n",
      "Following are the security requirements:\n",
      "SEC-1: AuthenticationThe system shall implement secure user authentication using\n",
      "industry-standard protocols to prevent unauthorized access.\n",
      "SEC-2: Data ProtectionUser data including quiz results, query history, and personal\n",
      "information shall be encrypted both in transit and at rest.\n",
      "13\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 19 ---\n",
      "\n",
      "2. Project Requirements\n",
      "SEC-3: API Key SecurityExternal API keys for DeepSeek shall be stored in environ-\n",
      "ment variables or secure vaults, never hardcoded in source code.\n",
      "SEC-4: Session ManagementUser sessions shall automatically expire after 24 hours of\n",
      "inactivity, requiring re-authentication for security.\n",
      "SEC-6: Input ValidationAll user inputs shall be sanitized and validated to prevent SQL\n",
      "injection, XSS attacks, and other security vulnerabilities.\n",
      "SEC-7: Classroom PrivacyClassroom sessions shall be private by default, accessible\n",
      "only to invited participants with valid classroom codes.\n",
      "14\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 20 ---\n",
      "\n",
      "Chapter 3\n",
      "System Overview\n",
      "Rehnuma is an intelligent animated tutoring system that revolutionizes probability and\n",
      "statistics education by generating personalized visual explanations on-demand through\n",
      "AI-driven workflows. The system operates through two interconnected pipelines: a Dataset\n",
      "Generation Workflow that creates a comprehensive repository of textbook problems, so-\n",
      "lutions, and Manim animation codes using DeepSeek Math 7B-RL and Claude Sonnet ,\n",
      "stored in JSON format and indexed in ChromaDB for semantic retrieval; and a RAG Pro-\n",
      "duction Workflow that processes student queries through prompt engineering, retrieves\n",
      "relevant reference problems, generates step-by-step solutions using DeepSeek Math, con-\n",
      "verts solutions into Manim code via DeepSeek Coder, and renders synchronized video an-\n",
      "imations with audio narration within 60 seconds. Beyond core animation generation, the\n",
      "system includes a Quiz System for knowledge assessment, a Real-Time QA System for\n",
      "instant text-based answers, a Personalized Dashboard for progress tracking and analytics,\n",
      "and a Classroom module for collaborative learning sessions. Built on a layered architec-\n",
      "ture with React.js frontend, FastAPI/Flask backend, integrated AI/ML APIs (DeepSeek\n",
      "Math, DeepSeek Coder, Claude Sonnet), and hybrid data storage (PostgreSQL for rela-\n",
      "tional data, ChromaDB for vector embeddings, JSON for animation metadata), Rehnuma\n",
      "provides students with an adaptive, accessible, and interactive platform that transforms\n",
      "abstract statistical concepts into clear, visual, and engaging learning experiences.\n",
      "3.1 Architectural Design\n",
      "Rehnuma follows a Layered Architecture combined with the Client–Server Pattern to\n",
      "achieve modularity, scalability, and maintainability. The system is decomposed into four\n",
      "primary layers:\n",
      "15\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 21 ---\n",
      "\n",
      "3. System Overview\n",
      "1. Presentation Layer (Frontend)\n",
      "Responsibilities:\n",
      "- Handles user interface and user interactions.\n",
      "- Implements responsive web design using React.js.\n",
      "- Manages user input validation and output display.\n",
      "Components:Query Input Interface, Animation Player, Quiz Interface, Dashboard UI,\n",
      "Classroom Interface.\n",
      "2. Application Layer (Backend Logic)\n",
      "Responsibilities:\n",
      "- Processes business logic and orchestrates workflows.\n",
      "- Implements FastAPI/Flask server for REST API endpoints.\n",
      "- Manages authentication, session handling, and routing.\n",
      "Components:Query Processor, Animation Generator, Quiz Engine, QA Handler, Class-\n",
      "room Manager.\n",
      "3. AI/ML Layer (Intelligence)\n",
      "Responsibilities:\n",
      "- Integrates external AI models and handles intelligent operations.\n",
      "- Manages API calls to DeepSeek Math, Code Llama-7B, and Lang Chain.\n",
      "- Implements RAG pipeline with prompt engineering.\n",
      "Components:DeepSeek Math, DeepSeek Coder Interface, Prompt Engineer, ChromaDB\n",
      "Manager.\n",
      "4. Data Layer (Storage)\n",
      "Responsibilities:\n",
      "- Manages persistent data storage and retrieval.\n",
      "- Implements PostgreSQL for relational data (users, quizzes, sessions).\n",
      "- Implements ChromaDB for vector embeddings and semantic search.\n",
      "- Implements JSON file storage for animation metadata.\n",
      "Components:User Database, Quiz Database, Vector Store, Media Storage.\n",
      "Inter-Layer Communication:\n",
      "Presentation↔Application: REST API (HTTP/HTTPS)\n",
      "Application↔AI/ML: API calls and internal function calls\n",
      "Application↔Data: Database queries (SQL, vector search)\n",
      "AI/ML↔Data: Vector embedding storage and retrieval\n",
      "16\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 22 ---\n",
      "\n",
      "3.2 Data Design\n",
      "Figure 3.1: Architecture Diagram\n",
      "3.2 Data Design\n",
      "Vector Database (ChromaDB) Collection: rehnuma_problems\n",
      "•Document:Problem description + solution text\n",
      "•Embedding:768-dimensional vector (generated using Sentence-Transformers)\n",
      "•Metadata:\n",
      "–problem_id\n",
      "–topic\n",
      "–difficulty\n",
      "–source_textbook\n",
      "–manim_code_path\n",
      "–solution_steps\n",
      "17\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 23 ---\n",
      "\n",
      "3. System Overview\n",
      "Storage Structure:\n",
      "ChromaDB Collection: \"rehnuma_problems\"\n",
      "Embeddings (vectors)\n",
      "Documents (text)\n",
      "Metadata (JSON)\n",
      "problem_id\n",
      "topic\n",
      "difficulty\n",
      "manim_code\n",
      "solution_json\n",
      "File Storage Structure\n",
      "/storage\n",
      "/animations\n",
      "/videos\n",
      "{animation_id}.mp4\n",
      "/audio\n",
      "{animation_id}.mp3\n",
      "/datasets\n",
      "problems_dataset.json\n",
      "/logs\n",
      "error_logs.txt\n",
      "api_usage_logs.txt\n",
      "JSON Dataset Format Example\n",
      "{\n",
      "\"problem_id\": \"prob_001\",\n",
      "\"description\": \"Calculate the probability of...\",\n",
      "\"topic\": \"conditional_probability\",\n",
      "\"difficulty\": \"intermediate\",\n",
      "\"solution_steps\": [\n",
      "\"Step 1: Identify the given information\",\n",
      "\"Step 2: Apply Bayes’ theorem\"\n",
      "],\n",
      "\"manim_code\": \"class ProbabilityAnimation(Scene):...\",\n",
      "\"metadata\": {\n",
      "\"source\": \"Ross Chapter 3\",\n",
      "18\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 24 ---\n",
      "\n",
      "3.3 Domain Model\n",
      "\"created_at\": \"2025-01-15\",\n",
      "\"validated\": true\n",
      "}\n",
      "}\n",
      "Data Flow Write Operations:\n",
      "• User generates animation→Store inanimationstable + video/audio files\n",
      "• Admin creates dataset entry→Store inPostgreSQL + ChromaDB + JSON\n",
      "• User takes quiz→Store inquiz_attemptstable\n",
      "Read Operations:\n",
      "• User queries→Retrieve embeddings fromChromaDB→Fetch metadata from\n",
      "JSON\n",
      "• User views dashboard→Aggregate data fromquiz_attempts+queries\n",
      "• User joins classroom→Queryclassroom_participants\n",
      "Data Synchronization:\n",
      "• PostgreSQL IDs map toChromaDB metadata\n",
      "• JSON files serve asbackup/export format\n",
      "• Regularbatch jobsensure data consistency across databases\n",
      "3.3 Domain Model\n",
      "The domain model for Rehnuma represents the key conceptual classes and their relation-\n",
      "ships within the system.\n",
      "Core Entities:\n",
      "User\n",
      "Attributes:userID, name, email, password, role, registrationDate\n",
      "Relationships:Creates Queries, Takes Quizzes, Joins Classrooms\n",
      "19\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 25 ---\n",
      "\n",
      "3. System Overview\n",
      "Query\n",
      "Attributes:queryID, queryText, timestamp, userID\n",
      "Relationships:Generates Animation, Retrieves References\n",
      "Animation\n",
      "Attributes:animationID, videoPath, audioPath, duration, generatedDate\n",
      "Relationships:Based on Solution, Uses ManimCode\n",
      "Solution\n",
      "Attributes:solutionID, steps, explanation, difficulty\n",
      "Relationships:Solves Problem, Generated from Query\n",
      "Problem\n",
      "Attributes:problemID, description, topic, difficulty, source\n",
      "Relationships:Has Solution, Stored in Dataset\n",
      "Dataset\n",
      "Attributes:datasetID, totalEntries, lastUpdated\n",
      "Relationships:Contains Problems, Stored in ChromaDB\n",
      "ManimCode\n",
      "Attributes:codeID, pythonCode, metadata, validationStatus\n",
      "Relationships:Generates Animation, Validated by Validator\n",
      "Quiz\n",
      "Attributes:quizID, topic, difficulty, createdDate\n",
      "Relationships:Contains Questions, Taken by User\n",
      "Question\n",
      "Attributes:questionID, text, options, correctAnswer, explanation\n",
      "Relationships:Part of Quiz\n",
      "QuizAttempt\n",
      "Attributes:attemptID, userID, quizID, score, timestamp\n",
      "Relationships:Records Performance\n",
      "Classroom\n",
      "20\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 26 ---\n",
      "\n",
      "3.3 Domain Model\n",
      "Attributes:classroomID, name, code, createdDate, creatorID\n",
      "Relationships:Has Participants, Contains Sessions\n",
      "Dashboard\n",
      "Attributes:dashboardID, userID, analyticsData\n",
      "Relationships:Displays Performance, Shows Progress\n",
      "Key Relationships:\n",
      "User (1)↔() Query\n",
      "Query (1)↔(1) Animation\n",
      "Animation (1)↔(1) Solution\n",
      "Solution (1)↔(1) Problem\n",
      "Dataset (1)↔() Problem\n",
      "User (1)↔() QuizAttempt\n",
      "Quiz (1)↔() Question\n",
      "Classroom (1)↔() User (as participants)\n",
      "User (1)↔(1) Dashboard\n",
      "21\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 27 ---\n",
      "\n",
      "3. System Overview\n",
      "Figure 3.2: Usecase Diagram\n",
      "22\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 28 ---\n",
      "\n",
      "3.4 Design Models\n",
      "3.4 Design Models\n",
      "3.4.1 Behavioral and Structural Diagrams\n",
      "3.4.1.1 Activity Diagram\n",
      "The activity diagram illustrates the workflow for the primary use case:Generate Ani-\n",
      "mated Explanation.\n",
      "Process Flow:\n",
      "Start: User opens application\n",
      "Submit Query: User enters natural language query\n",
      "Validate Input: System checks query validity\n",
      "Decision:Is query valid?\n",
      "No→Display error message→Return to Submit Query\n",
      "Yes→Continue\n",
      "Engineer Prompt: Enhance query for better retrieval\n",
      "Retrieve References: Search ChromaDB for similar problems\n",
      "Generate Solution: Use DeepSeek Math with context\n",
      "Validate Solution: Check mathematical correctness\n",
      "Decision:Is solution valid?\n",
      "No→Regenerate solution (max 3 attempts)→Return to Generate Solution\n",
      "Yes→Continue\n",
      "Generate Manim Code: Use DeepSeek Coder\n",
      "Render Animation: Execute Manim rendering\n",
      "Generate Audio: Create narration using gtts\n",
      "Sync Audio-Video: Combine audio and video\n",
      "Store Result: Save to database\n",
      "Display Animation: Present to user\n",
      "End: User views explanation\n",
      "Parallel Activities:\n",
      "- While rendering animation, generate audio narration (concurrent).\n",
      "- While displaying animation, update dashboard analytics (background).\n",
      "23\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 29 ---\n",
      "\n",
      "3. System Overview\n",
      "Figure 3.3: Activity Diagram\n",
      "24\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 30 ---\n",
      "\n",
      "3.4 Design Models\n",
      "3.4.1.2 Class Diagram\n",
      "The class diagram represents the structural view of the system with all major classes, their\n",
      "attributes, and relationships.\n",
      "Key Design Decisions:\n",
      "-Information Expert Pattern:Classes are responsible for data they own (e.g.,Query\n",
      "class validates its own input).\n",
      "-Creator Pattern:Factory classes create complex objects (e.g.,AnimationFactorycre-\n",
      "ates Animation objects).\n",
      "-Controller Pattern:Dedicated controller classes handle system events (e.g.,QueryCon-\n",
      "troller).\n",
      "-Low Coupling:Minimal dependencies between classes through interfaces.\n",
      "-High Cohesion:Each class has focused, related responsibilities.\n",
      "25\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 31 ---\n",
      "\n",
      "3. System Overview\n",
      "Figure 3.4: Class Diagram\n",
      "26\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 32 ---\n",
      "\n",
      "3.4 Design Models\n",
      "3.4.1.3 Sequence Diagram\n",
      "The sequence diagram illustrates the interaction between the major system components\n",
      "and external actors over time for theAnimation Generationuse case. It details the\n",
      "message flow, order of operations, and return values exchanged among the entities.\n",
      "*Participants\n",
      "•Cashier (End User)– Initiates the animation generation process by submitting a\n",
      "query.\n",
      "•System (Green Box)– Core Rehnuma system responsible for handling user input,\n",
      "managing workflows, and coordinating AI interactions.\n",
      "•External AI Services (DeepSeek, Code-Llama)– External APIs responsible for\n",
      "mathematical reasoning, code generation, and language understanding.\n",
      "*Sequence Flow\n",
      "Query Submission Phase\n",
      "1. User enters a query in the user interface.\n",
      "2. The system receives and records the query string.\n",
      "Query Processing Phase\n",
      "1. The system validates the query input.\n",
      "2. Prompt engineering enhances the query for optimal AI processing.\n",
      "3. ChromaDB is queried to retrieve similar reference problems.\n",
      "Solution Generation Phase\n",
      "1. DeepSeek Math receives the context and query.\n",
      "2. It generates a detailed step-by-step mathematical solution.\n",
      "3. The system validates the generated solution for correctness.\n",
      "27\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 33 ---\n",
      "\n",
      "3. System Overview\n",
      "Code Generation Phase\n",
      "1. DeepSeek Coder receives the validated solution.\n",
      "2. It produces Manim-compatible Python code for animation rendering.\n",
      "Animation Rendering Phase\n",
      "1. The system executes the Manim rendering engine.\n",
      "2. Google Text-to-Speech (gTTS) generates narration audio.\n",
      "3. The video and audio tracks are synchronized.\n",
      "Output Delivery Phase\n",
      "1. The rendered animation is stored in media storage.\n",
      "2. Video and audio file paths are returned to the user interface.\n",
      "3. The completed animation is displayed to the user.\n",
      "*Alternative Paths\n",
      "• Invalid query input→Display error message and prompt user to retry.\n",
      "• No references found→Use default example problems and continue.\n",
      "• Solution generation fails (after three retries)→Show appropriate error message.\n",
      "• Rendering failure→Suggest simplifying the user query.\n",
      "*Performance Metrics\n",
      "• Average time from query submission to animation display:60 seconds (95th per-\n",
      "centile).\n",
      "• Each phase includes timeout handling for fault tolerance.\n",
      "*Message Types\n",
      "•Synchronous calls(solid arrows): Communication betweenQueryControllerand\n",
      "service modules.\n",
      "•Asynchronous operations: Background rendering of animation and audio process-\n",
      "ing.\n",
      "•Return values(dashed arrows): Results and file paths sent back to the user inter-\n",
      "face.\n",
      "28\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 34 ---\n",
      "\n",
      "3.4 Design Models\n",
      "Figure 3.5: Sequence Diagram\n",
      "29\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 35 ---\n",
      "\n",
      "3. System Overview\n",
      "3.4.1.4 DataFlow Diagram\n",
      "The Data Flow Diagram (DFD) shows how data moves through the Rehnuma system from\n",
      "user input to final output.\n",
      "External Entities\n",
      "•User:Submits queries and views animations\n",
      "•Administrator:Creates dataset entries\n",
      "•DeepSeek Math:AI service for solution and code generation\n",
      "•LLM:AI service for Manim code generation\n",
      "Processes\n",
      "Main RAG Flow:\n",
      "1.Validate Query:Checks user input validity\n",
      "2.Enhance Query:Applies prompt engineering\n",
      "3.Retrieve Context:Searches ChromaDB for similar problems\n",
      "4.Generate Solution:Creates step-by-step solution via DeepSeek Math\n",
      "5.Validate Solution:Verifies correctness using SymPy/NumPy\n",
      "6.Generate Code:Converts solution to Manim code via DeepSeek Math\n",
      "7.Render Video:Executes Manim rendering\n",
      "8.Generate Audio:Creates narration using TTS\n",
      "9.Sync Media:Combines video and audio\n",
      "Dataset Flow:\n",
      "10.Create Dataset:Processes problem-solution pairs, generates code, stores in dataset\n",
      "Data Stores\n",
      "1.D1 - Users:User credentials and profiles\n",
      "2.D2 - ChromaDB:Vector embeddings for semantic search\n",
      "3.D3 - Animations:Rendered video and audio files\n",
      "30\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 36 ---\n",
      "\n",
      "3.4 Design Models\n",
      "4.D4 - Dataset:Problems, solutions, and Manim code in JSON\n",
      "Data Flows\n",
      "Primary Flow:User submits query→validated→enhanced→context retrieved→\n",
      "solution generated→validated→code generated→video and audio rendered in parallel\n",
      "→synchronized→returned to user.\n",
      "Dataset Flow:Administrator inputs problem→LLM generate code→stored in dataset\n",
      "→indexed in ChromaDB for future retrieval.\n",
      "Key Feature:Processes 7.0 and 8.0 execute in parallel to optimize performance, then\n",
      "converge at 9.0 for synchronization.\n",
      "31\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 37 ---\n",
      "\n",
      "3. System Overview\n",
      "Figure 3.6: DataFlow Diagram\n",
      "32\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 38 ---\n",
      "\n",
      "Chapter 4\n",
      "Implementation and Testing\n",
      "This chapter describes the implementation details of the Rehnuma system, including al-\n",
      "gorithm design, external API integration, and comprehensive testing strategies. The im-\n",
      "plementation leverages state-of-the-art AI models accessed through Groq API to ensure\n",
      "cost-effective and high-performance solution generation and code synthesis.\n",
      "4.1 Algorithm Design\n",
      "The core functionality of Rehnuma relies on several key algorithms that orchestrate the\n",
      "animation generation pipeline. This section presents the pseudocode for the main algo-\n",
      "rithms used in the system. The primary algorithm coordinates the entire workflow from\n",
      "user query to final animation output. It implements a retrieval-augmented generation ap-\n",
      "proach with error handling and retry mechanisms.\n",
      "[H] RAG Animation Generation Pipeline [1] userQuery: String, userID: Integer anima-\n",
      "tionPath: String or ErrorMessage: String queryID←generateUniqueID() logQuery(queryID,\n",
      "userQuery, userID) NOT validateQuery(userQuery) \"Error: Invalid query format\" en-\n",
      "hancedQuery←promptEngineer(userQuery) queryEmbedding←generateEmbedding(enhancedQuery)\n",
      "referenceProblems←chromaDB.similaritySearch(queryEmbedding, k=4) referenceProb-\n",
      "lems is empty referenceProblems←getDefaultExamples() context←formatContext(referenceProblems)\n",
      "retryCount←0 maxRetries←3 retryCount<maxRetries solution←callMistral7B(enhancedQuery,\n",
      "context) validateSolution(solution)breakretryCount←retryCount + 1 retryCount ==\n",
      "maxRetries \"Error: Solution generation failed after 3 attempts\" manimCode←call-\n",
      "CodeLlama70B(solution) NOT validateManimSyntax(manimCode) \"Error: Invalid Manim\n",
      "code generated\" videoPath←renderManimVideo(manimCode) audioPath←generateAu-\n",
      "dioNarration(solution) animationPath←synchronizeMediaFiles(videoPath, audioPath)\n",
      "saveAnimationMetadata(queryID, animationPath, solution) animationPath\n",
      "33\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 39 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "4.1.1 Vector Similarity Search Algorithm\n",
      "This algorithm implements semantic search in ChromaDB using HNSW (Hierarchical\n",
      "Navigable Small World) index to retrieve the most relevant reference problems for a given\n",
      "query.\n",
      "[H] Semantic Similarity Search with HNSW [1] query: String, k: Integer topKProblems:\n",
      "List[Problem] queryEmbedding←generateEmbedding(query) normalizedQuery←nor-\n",
      "malize(queryEmbedding) similarityScores←empty list hnsw_index←chromaDB.getHNSWIndex()\n",
      "each problem in hnsw_index problemEmbedding←problem.getEmbedding() similarity\n",
      "←cosineSimilarity(normalizedQuery, problemEmbedding) similarityScores.add((problem,\n",
      "similarity)) sortedProblems←sort(similarityScores, descending=True) topKProblems←\n",
      "sortedProblems[0:k] topKProblems\n",
      "Cosine Similarity Calculation:\n",
      "cosine_similarity(A,B) =A·B\n",
      "||A||×||B||(4.1)\n",
      "For normalized vectors (||A||=||B||=1):\n",
      "cosine_similarity(A,B) =A·B(4.2)\n",
      "4.1.2 Dataset Generation Algorithm\n",
      "This algorithm processes textbook problems to create structured dataset entries with val-\n",
      "idated code and metadata, following the pipeline described in the RAG implementation\n",
      "documentation.\n",
      "[H] Dataset Entry Creation with Text Parsing [1] problemDescription: String, solution:\n",
      "String, admin: User datasetEntry: DatasetEntry or ErrorMessage: String entryID←gen-\n",
      "erateUniqueID() topic←extractTopicFromText(problemDescription) problemText, solu-\n",
      "tionText←splitProblemAndSolution(problemDescription) theory←generateTheoryDe-\n",
      "scription(topic, problemText) pythonCode←callMistral7B(problemText, solutionText)\n",
      "NOT validateWithSymPy(pythonCode) \"Error: Python code validation failed\" NOT vali-\n",
      "dateWithNumPy(pythonCode) \"Error: Numerical validation failed\" manimCode←call-\n",
      "CodeLlama70B(solutionText, pythonCode) metadata←createMetadata(topic, problem-\n",
      "Text) metadata.add(\"difficulty\", classifyDifficulty(problemText)) metadata.add(\"animation_hint\",\n",
      "generateAnimationMetadata(topic)) datasetEntry←createEntry(entryID, problemText,\n",
      "theory, solutionText, pythonCode, manimCode, metadata) saveToJSONStorage(datasetEntry)\n",
      "embedding←generateEmbedding(problemText + solutionText) chromaDB.indexEntry(entryID,\n",
      "embedding, metadata) datasetEntry\n",
      "34\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 40 ---\n",
      "\n",
      "4.2 External APIs/SDKs\n",
      "4.1.3 Quiz Generation Algorithm\n",
      "This algorithm generates adaptive quizzes based on user queries and performance history.\n",
      "[H] Adaptive Quiz Generation [1] userQuery: String, userID: Integer, difficulty: String\n",
      "quiz: Quiz relatedProblems←searchDataset(userQuery) userHistory←getUserQuizHis-\n",
      "tory(userID) weakTopics←identifyWeakTopics(userHistory) questionPool←empty list\n",
      "topic in weakTopics topicProblems←filterByTopic(relatedProblems, topic) question-\n",
      "Pool.addAll(topicProblems) selectedQuestions←randomSample(questionPool, count=10)\n",
      "each question in selectedQuestions mcqOptions←callMistral7B(\"Generate 4 options\n",
      "for: \" + question) explanation←callMistral7B(\"Explain solution: \" + question) ques-\n",
      "tion.setOptions(mcqOptions) question.setExplanation(explanation) quiz←createQuiz(selectedQuestions,\n",
      "difficulty) saveQuizToDatabase(quiz) quiz\n",
      "4.2 External APIs/SDKs\n",
      "The Rehnuma system integrates multiple external APIs and software development kits\n",
      "to achieve its functionality. The following table describes each external dependency, its\n",
      "purpose, and specific endpoints or functions utilized.\n",
      "35\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 41 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "API and Version Description Purpose Endpoint/Function\n",
      "Groq API (Mistral 7B) Cloud-hosted inference API for\n",
      "Mistral 7B model on free tierSolution genera-\n",
      "tion and mathemat-\n",
      "ical reasoning/openai/v1/chat/\n",
      "completions\n",
      "Groq API (Code\n",
      "Llama 3.3 70B)Cloud-hosted inference API for\n",
      "Code Llama 3.3 70B on free tierManim-compatible\n",
      "Python code gener-\n",
      "ation/openai/v1/chat/\n",
      "completions\n",
      "ChromaDB v0.4.18 Open-source vector database for\n",
      "embeddingsSemantic search\n",
      "and retrieval of\n",
      "reference problemsCollection.query(),\n",
      "Collection.add()\n",
      "Sentence-\n",
      "Transformers v2.2.2Python library for generating\n",
      "sentence embeddingsConverting text to\n",
      "768-dim vectors\n",
      "for semantic searchSentenceTransformer.encode()\n",
      "Manim Community\n",
      "Edition v0.18.0Mathematical animation engine Rendering anima-\n",
      "tions from Python\n",
      "codemanim render,\n",
      "Scene.construct()\n",
      "Google Text-to-\n",
      "Speech (gTTS) v2.4.0Text-to-speech conversion li-\n",
      "braryGenerating audio\n",
      "narration for ani-\n",
      "mationsgTTS.save(),\n",
      "gTTS(text,\n",
      "lang)\n",
      "FFmpeg v6.0 Multimedia framework for video\n",
      "processingSynchronizing\n",
      "video and audio\n",
      "filesffmpeg -i\n",
      "video.mp4 -i\n",
      "audio.mp3\n",
      "SymPy v1.12 Symbolic mathematics library Validating mathe-\n",
      "matical expressions\n",
      "and equationssympify(),\n",
      "simplify(),\n",
      "solve()\n",
      "NumPy v1.24.3 Numerical computing library Validating numeri-\n",
      "cal computationsnumpy.allclose(),\n",
      "numpy.isclose()\n",
      "FastAPI v0.104.1 Modern web framework for\n",
      "building APIsBackend REST\n",
      "API implementa-\n",
      "tion@app.post(),\n",
      "@app.get()\n",
      "PostgreSQL v15.4 Relational database manage-\n",
      "ment systemStoring user data,\n",
      "quizzes, and ani-\n",
      "mation metadataSQL queries via\n",
      "psycopg2\n",
      "React v18.2.0 JavaScript library for building\n",
      "UIFrontend user in-\n",
      "terfaceComponents,\n",
      "Hooks, State man-\n",
      "agement\n",
      "Table 4.1: External APIs and SDKs Used in Rehnuma\n",
      "36\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 42 ---\n",
      "\n",
      "4.2 External APIs/SDKs\n",
      "4.2.1 Groq API Integration Details\n",
      "Rehnuma leverages Groq’s cloud infrastructure to access Mistral 7B and Code Llama 3.3\n",
      "70B models on the free tier, significantly reducing computational costs while maintaining\n",
      "high performance. The integration follows these specifications:\n",
      "Authentication:API key-based authentication using bearer token\n",
      "headers = {\n",
      "\"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
      "\"Content-Type\": \"application/json\"\n",
      "}\n",
      "Request Format for Mistral 7B (Solution Generation):\n",
      "{\n",
      "\"model\": \"mistral-7b-instruct\",\n",
      "\"messages\": [\n",
      "{\n",
      "\"role\": \"system\",\n",
      "\"content\": \"You are a mathematics tutor...\"\n",
      "},\n",
      "{\n",
      "\"role\": \"user\",\n",
      "\"content\": \"Explain Bayes Theorem...\"\n",
      "}\n",
      "],\n",
      "\"temperature\": 0.7,\n",
      "\"max_tokens\": 2048\n",
      "}\n",
      "Request Format for Code Llama 3.3 70B (Code Generation):\n",
      "{\n",
      "\"model\": \"llama-3.3-70b-versatile\",\n",
      "\"messages\": [\n",
      "{\n",
      "\"role\": \"system\",\n",
      "\"content\": \"Generate Manim Python code...\"\n",
      "},\n",
      "{\n",
      "\"role\": \"user\",\n",
      "37\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 43 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "\"content\": \"<solution_text>\"\n",
      "}\n",
      "],\n",
      "\"temperature\": 0.3,\n",
      "\"max_tokens\": 4096\n",
      "}\n",
      "Rate Limits (Free Tier):\n",
      "• Mistral 7B: 30 requests per minute\n",
      "• Code Llama 3.3 70B: 20 requests per minute\n",
      "• Implemented exponential backoff retry mechanism for rate limit handling\n",
      "38\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 44 ---\n",
      "\n",
      "4.3 Testing Details\n",
      "Figure 4.1: Dashboard\n",
      "4.3 Testing Details\n",
      "Comprehensive testing was conducted to ensure system reliability, correctness, and per-\n",
      "formance. This section details unit testing, integration testing, and system testing strate-\n",
      "gies.\n",
      "4.3.1 Unit Testing\n",
      "Unit tests were written for all critical components to verify individual function correctness\n",
      "in isolation. The following subsections present key unit tests implemented using Python’s\n",
      "pytestframework.\n",
      "4.3.1.1 Test Case 1: Query Validation\n",
      "Purpose:Verify that the query validation function correctly identifies valid and invalid\n",
      "user inputs.\n",
      "Test Code:\n",
      "import pytest\n",
      "from app.validators import validateQuery\n",
      "def test_valid_query():\n",
      "39\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 45 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "Figure 4.2: Dashboard-2\n",
      "valid_query = \"Explain Bayes Theorem with an example\"\n",
      "assert validateQuery(valid_query) == True\n",
      "def test_empty_query():\n",
      "empty_query = \"\"\n",
      "assert validateQuery(empty_query) == False\n",
      "def test_query_too_long():\n",
      "long_query = \"a\" * 501 # Exceeds 500 character limit\n",
      "assert validateQuery(long_query) == False\n",
      "def test_query_with_special_chars():\n",
      "special_query = \"What is P(A|B)?\"\n",
      "assert validateQuery(special_query) == True\n",
      "def test_query_only_whitespace():\n",
      "whitespace_query = \" \\n\\t \"\n",
      "assert validateQuery(whitespace_query) == False\n",
      "Expected Results:\n",
      "• Valid queries returnTrue\n",
      "• Empty or whitespace-only queries returnFalse\n",
      "40\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 46 ---\n",
      "\n",
      "4.3 Testing Details\n",
      "Figure 4.3: Solution-Generation\n",
      "• Queries exceeding 500 characters returnFalse\n",
      "• Queries with mathematical symbols are accepted\n",
      "Actual Results:All tests passed successfully.\n",
      "4.3.1.2 Test Case 2: Vector Similarity Search\n",
      "Purpose:Verify that the ChromaDB semantic search returns relevant problems based on\n",
      "query similarity.\n",
      "Test Code:\n",
      "import pytest\n",
      "from app.database import ChromaDBManager\n",
      "@pytest.fixture\n",
      "def chroma_db():\n",
      "db = ChromaDBManager()\n",
      "41\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 47 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "db.add_test_data([\n",
      "{\"id\": \"1\", \"text\": \"Bayes theorem problem\",\n",
      "\"topic\": \"probability\"},\n",
      "{\"id\": \"2\", \"text\": \"Normal distribution example\",\n",
      "\"topic\": \"statistics\"},\n",
      "{\"id\": \"3\", \"text\": \"Conditional probability question\",\n",
      "\"topic\": \"probability\"}\n",
      "])\n",
      "return db\n",
      "def test_similarity_search_returns_correct_count(chroma_db):\n",
      "query = \"probability problem\"\n",
      "results = chroma_db.search(query, k=2)\n",
      "assert len(results) == 2\n",
      "def test_similarity_search_returns_relevant_results(chroma_db):\n",
      "query = \"Bayes theorem\"\n",
      "results = chroma_db.search(query, k=1)\n",
      "assert \"Bayes\" in results[0][\"text\"]\n",
      "def test_similarity_search_with_empty_query(chroma_db):\n",
      "query = \"\"\n",
      "with pytest.raises(ValueError):\n",
      "chroma_db.search(query, k=3)\n",
      "def test_similarity_search_ranking(chroma_db):\n",
      "query = \"conditional probability\"\n",
      "results = chroma_db.search(query, k=3)\n",
      "# Most similar result should be first\n",
      "assert \"Conditional\" in results[0][\"text\"] or \\\n",
      "\"probability\" in results[0][\"text\"]\n",
      "Expected Results:\n",
      "• Search returns exactly k results when k results exist\n",
      "• Most similar problems ranked first\n",
      "• Empty query raises ValueError\n",
      "• Results contain relevant keywords\n",
      "Actual Results:All tests passed. Average similarity score for relevant results: 0.87/1.0.\n",
      "42\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 48 ---\n",
      "\n",
      "4.3 Testing Details\n",
      "4.3.1.3 Test Case 3: Manim Code Validation\n",
      "Purpose:Verify that generated Manim code passes syntax validation before rendering.\n",
      "Test Code:\n",
      "import pytest\n",
      "from app.validators import validateManimSyntax\n",
      "def test_valid_manim_code():\n",
      "valid_code = \"\"\"\n",
      "from manim import *\n",
      "class Example(Scene):\n",
      "def construct(self):\n",
      "text = Text(\"Hello\")\n",
      "self.play(Write(text))\n",
      "\"\"\"\n",
      "assert validateManimSyntax(valid_code) == True\n",
      "def test_invalid_python_syntax():\n",
      "invalid_code = \"\"\"\n",
      "from manim import *\n",
      "class Example(Scene)\n",
      "def construct(self) # Missing colons\n",
      "text = Text(\"Hello\")\n",
      "\"\"\"\n",
      "assert validateManimSyntax(invalid_code) == False\n",
      "def test_missing_scene_class():\n",
      "no_scene = \"\"\"\n",
      "from manim import *\n",
      "def animate():\n",
      "text = Text(\"Hello\")\n",
      "\"\"\"\n",
      "assert validateManimSyntax(no_scene) == False\n",
      "def test_missing_construct_method():\n",
      "no_construct = \"\"\"\n",
      "from manim import *\n",
      "class Example(Scene):\n",
      "43\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 49 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "def render(self):\n",
      "pass\n",
      "\"\"\"\n",
      "assert validateManimSyntax(no_construct) == False\n",
      "def test_valid_code_with_math():\n",
      "math_code = \"\"\"\n",
      "from manim import *\n",
      "class Example(Scene):\n",
      "def construct(self):\n",
      "formula = MathTex(r\"P(A|B) = \\\\frac{P(B|A)P(A)}{P(B)}\")\n",
      "self.play(Write(formula))\n",
      "\"\"\"\n",
      "assert validateManimSyntax(math_code) == True\n",
      "Expected Results:\n",
      "• Valid Manim code with proper Scene class returnsTrue\n",
      "• Code with Python syntax errors returnsFalse\n",
      "• Code without Scene class returnsFalse\n",
      "• Code without construct() method returnsFalse\n",
      "Actual Results:All tests passed successfully.\n",
      "44\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 50 ---\n",
      "\n",
      "4.3 Testing Details\n",
      "Figure 4.4: Manim-Validation\n",
      "4.3.1.4 Test Case 4: Solution Validation with SymPy\n",
      "Purpose:Verify that mathematical solutions are validated correctly using SymPy.\n",
      "Test Code:\n",
      "import pytest\n",
      "from app.validators import validateSolution\n",
      "def test_correct_probability_calculation():\n",
      "solution = {\n",
      "\"equation\": \"P(A|B) = P(B|A) * P(A) / P(B)\",\n",
      "\"values\": {\"P(B|A)\": 0.8, \"P(A)\": 0.01, \"P(B)\": 0.0196},\n",
      "\"result\": 0.408\n",
      "}\n",
      "assert validateSolution(solution) == True\n",
      "def test_incorrect_calculation():\n",
      "solution = {\n",
      "\"equation\": \"P(A|B) = P(B|A) * P(A) / P(B)\",\n",
      "45\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 51 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "\"values\": {\"P(B|A)\": 0.8, \"P(A)\": 0.01, \"P(B)\": 0.0196},\n",
      "\"result\": 0.5 # Wrong result\n",
      "}\n",
      "assert validateSolution(solution) == False\n",
      "def test_invalid_probability_range():\n",
      "solution = {\n",
      "\"equation\": \"P(A) = 1.5\", # Probability > 1\n",
      "\"result\": 1.5\n",
      "}\n",
      "assert validateSolution(solution) == False\n",
      "def test_algebra_validation():\n",
      "solution = {\n",
      "\"equation\": \"x^2 - 5x + 6 = 0\",\n",
      "\"solutions\": [2, 3],\n",
      "\"method\": \"factoring\"\n",
      "}\n",
      "assert validateSolution(solution) == True\n",
      "def test_division_by_zero_detection():\n",
      "solution = {\n",
      "\"equation\": \"y = 1 / 0\",\n",
      "\"result\": \"undefined\"\n",
      "}\n",
      "assert validateSolution(solution) == False\n",
      "Expected Results:\n",
      "• Correct mathematical calculations returnTrue\n",
      "• Incorrect calculations returnFalse\n",
      "• Probabilities outside [0,1] range returnFalse\n",
      "• Division by zero is detected and rejected\n",
      "Actual Results:All tests passed. SymPy successfully validated 98% of test cases.\n",
      "46\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 52 ---\n",
      "\n",
      "4.3 Testing Details\n",
      "4.3.2 Integration Testing\n",
      "Integration tests verify that multiple components work correctly together. Key integration\n",
      "test scenarios:\n",
      "4.3.2.1 End-to-End Animation Generation Test\n",
      "Purpose:Verify complete workflow from query to animation output.\n",
      "Test Procedure:\n",
      "1. Submit test query: \"Explain Bayes Theorem with medical diagnosis example\"\n",
      "2. Verify query validation passes\n",
      "3. Verify ChromaDB retrieval returns 3 reference problems\n",
      "4. Verify Mistral 7B generates solution (via Groq API)\n",
      "5. Verify SymPy validation passes\n",
      "6. Verify Code Llama 3.3 70B generates Manim code (via Groq API)\n",
      "7. Verify Manim rendering produces MP4 file\n",
      "8. Verify gTTS generates audio file\n",
      "9. Verify FFmpeg synchronizes media files\n",
      "10. Verify animation metadata saved to database\n",
      "11. Measure total execution time\n",
      "Expected Results:\n",
      "• Complete workflow executes without errors\n",
      "• Final animation file size: 5-15 MB\n",
      "• Total execution time: < 90 seconds\n",
      "• Video resolution: 720p (1280x720)\n",
      "• Audio quality: 44.1kHz, 128kbps\n",
      "Actual Results:\n",
      "47\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 53 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "• All components integrated successfully\n",
      "• Average animation file size: 8.3 MB\n",
      "• Average execution time: 67 seconds (well within target)\n",
      "• Success rate: 94% (56/60 test queries)\n",
      "• Failures primarily due to API rate limits\n",
      "4.3.2.2 Quiz Generation and Submission Flow Test\n",
      "Purpose:Test complete quiz workflow from generation to grading.\n",
      "Test Code:\n",
      "def test_quiz_workflow():\n",
      "# Step 1: Generate quiz\n",
      "user_id = create_test_user()\n",
      "quiz = generate_quiz(\n",
      "user_id=user_id,\n",
      "topic=\"conditional_probability\",\n",
      "difficulty=\"intermediate\"\n",
      ")\n",
      "assert quiz is not None\n",
      "assert len(quiz.questions) == 10\n",
      "# Step 2: Submit answers\n",
      "answers = {\n",
      "\"q1\": \"A\", \"q2\": \"C\", \"q3\": \"B\", \"q4\": \"D\",\n",
      "\"q5\": \"A\", \"q6\": \"B\", \"q7\": \"C\", \"q8\": \"A\",\n",
      "\"q9\": \"D\", \"q10\": \"B\"\n",
      "}\n",
      "result = submit_quiz_answers(user_id, quiz.id, answers)\n",
      "# Step 3: Verify grading\n",
      "assert result.score is not None\n",
      "assert 0 <= result.score <= 100\n",
      "assert result.feedback is not None\n",
      "# Step 4: Verify dashboard update\n",
      "dashboard = get_user_dashboard(user_id)\n",
      "assert quiz.id in dashboard.quiz_history\n",
      "48\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 54 ---\n",
      "\n",
      "4.3 Testing Details\n",
      "assert dashboard.total_quizzes_taken == 1\n",
      "Expected Results:\n",
      "• Quiz generated with 10 questions\n",
      "• Score calculated correctly (0-100)\n",
      "• Feedback provided for each question\n",
      "• Dashboard updated with quiz history\n",
      "Actual Results:All integration tests passed. Average quiz generation time: 12 seconds.\n",
      "49\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 55 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "Figure 4.5: Animation-Calculation\n",
      "4.3.3 Performance Testing\n",
      "Performance tests were conducted to verify system meets non-functional requirements.\n",
      "4.3.3.1 Load Testing Results\n",
      "Test Configuration:\n",
      "• Tool: Apache JMeter 5.5\n",
      "• Concurrent users: 50 simultaneous requests\n",
      "• Duration: 30 minutes\n",
      "• Test queries: Mix of simple and complex probability problems\n",
      "Results:\n",
      "50\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 56 ---\n",
      "\n",
      "4.3 Testing Details\n",
      "Figure 4.6: Solution\n",
      "Metric Target Actual Status\n",
      "Animation generation time (95th %) 90s 82s Pass\n",
      "Real-time QA response time 5s 3.2s Pass\n",
      "Quiz loading time 3s 2.1s Pass\n",
      "Dashboard loading time 5s 4.3s Pass\n",
      "Concurrent user support 100 100 Pass\n",
      "ChromaDB query time (95th %) 500ms 380ms Pass\n",
      "System uptime 99% 99.2% Pass\n",
      "Table 4.2: Performance Testing Results\n",
      "4.3.3.2 Stress Testing\n",
      "Purpose:Determine system breaking point under extreme load.\n",
      "Test Procedure:\n",
      "• Gradually increase concurrent users from 50 to 250\n",
      "• Monitor response times and error rates\n",
      "• Identify bottlenecks\n",
      "Results:\n",
      "51\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 57 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "• System stable up to 150 concurrent users\n",
      "• Performance degradation begins at 175 users\n",
      "• Groq API rate limits hit at 200+ users\n",
      "• Recommendation: Implement request queuing for >150 users\n",
      "52\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 58 ---\n",
      "\n",
      "4.3 Testing Details\n",
      "Figure 4.7: Testcases\n",
      "4.3.4 Security Testing\n",
      "4.3.4.1 SQL Injection Testing\n",
      "Test Code:\n",
      "def test_sql_injection_prevention():\n",
      "# Attempt SQL injection in query\n",
      "malicious_query = \"’; DROP TABLE users; --\"\n",
      "response = submit_query(malicious_query)\n",
      "# Verify query sanitized\n",
      "assert \"Error: Invalid query\" in response\n",
      "# Verify database intact\n",
      "user_count = count_users_in_database()\n",
      "assert user_count > 0 # Table not dropped\n",
      "Result:All SQL injection attempts successfully blocked by input sanitization.\n",
      "53\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 59 ---\n",
      "\n",
      "4. Implementation and Testing\n",
      "4.3.4.2 API Key Security Testing\n",
      "Test Procedure:\n",
      "1. Attempt to access Groq API without authentication\n",
      "2. Check for hardcoded API keys in source code\n",
      "3. Verify API keys stored in environment variables\n",
      "4. Test session expiration after 24 hours\n",
      "Results:\n",
      "• No hardcoded API keys found in repository\n",
      "• All API keys properly stored in.envfile\n",
      "• Unauthorized API access blocked\n",
      "• Session expiration working correctly\n",
      "4.3.5 Known Issues and Limitations\n",
      "1.Groq API Rate Limits:Free tier limits to 30 requests/minute for Mistral 7B. Im-\n",
      "plemented exponential backoff, but high concurrent load may experience delays.\n",
      "2.Animation Rendering Time:Complex Manim animations with extensive LaTeX\n",
      "formulas occasionally exceed 90-second target (observed in 6% of test cases).\n",
      "3.ChromaDB Scalability:Performance degrades with >10,000 indexed problems.\n",
      "Plan to implement sharding for production deployment.\n",
      "4.Audio-Video Sync:Rare desynchronization (< 1% of cases) when audio duration\n",
      "significantly exceeds video duration.\n",
      "54\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 60 ---\n",
      "\n",
      "55\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 61 ---\n",
      "\n",
      "A. Appendices\n",
      "Appendix A\n",
      "Appendices\n",
      "A.1 Appendix A\n",
      "A.1.1 Use Case Diagram example (Rehnuma)\n",
      "Figure A.1: Use Case Diagram for Rehnuma\n",
      "56\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 62 ---\n",
      "\n",
      "A.1 Appendix A\n",
      "A.1.2 Detail Use Case Example\n",
      "57\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 63 ---\n",
      "\n",
      "A. Appendices\n",
      "Figure A.2: Detailed Use Case Example of Rehnuma\n",
      "58\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 64 ---\n",
      "\n",
      "A.2 Appendix B\n",
      "A.2 Appendix B\n",
      "A.2.1 Class Diagram\n",
      "Figure A.3: Class Diagram for Rehnuma\n",
      "59\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 65 ---\n",
      "\n",
      "A. Appendices\n",
      "A.3 Appendix C\n",
      "A.3.1 Architecture Pattern Example\n",
      "Figure A.4: Architecture Pattern For Rehnuma\n",
      "60\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 66 ---\n",
      "\n",
      "A.3 Appendix C\n",
      "61\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 67 ---\n",
      "\n",
      "A. Appendices\n",
      "A.4 Appendix D\n",
      "A.4.1 Activity Diagram\n",
      "Figure A.5: Activity Diagram For Rehnuma62\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 68 ---\n",
      "\n",
      "A.4 Appendix D\n",
      "A.4.2 Sequence Diagram\n",
      "63\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 69 ---\n",
      "\n",
      "A. Appendices\n",
      "Figure A.6: Sequence Diagram\n",
      "64\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 70 ---\n",
      "\n",
      "A.4 Appendix D\n",
      "A.4.3 Data Flow Diagram\n",
      "65\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Page 71 ---\n",
      "\n",
      "A. Appendices\n",
      "Figure A.7: Data Flow Diagram for Rehnuma\n",
      "66\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import sys\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file page by page and print it.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the PDF file\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            # Create a PDF reader object\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            # Get total number of pages\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            print(f\"Total pages in PDF: {num_pages}\\n\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            # Extract text from each page\n",
    "            for page_num in range(num_pages):\n",
    "                # Get the page\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                \n",
    "                # Extract text from the page\n",
    "                text = page.extract_text()\n",
    "                \n",
    "                # Print page information and text\n",
    "                print(f\"\\n--- Page {page_num + 1} ---\\n\")\n",
    "                print(text)\n",
    "                print(\"\\n\" + \"=\" * 80)\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{pdf_path}' not found.\")\n",
    "    except PyPDF2.errors.PdfReadError:\n",
    "        print(f\"Error: '{pdf_path}' is not a valid PDF file or is corrupted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    pdf_path = \"report.pdf\"\n",
    "    extract_text_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0642d61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP25-119-D-Rehnuma Project Team Faseeh Iqbal 22I-1856 Ahmad Hasan 22I-1945 Manhab Zafar 22I-1957 Session 2022-2026 Supervised by Ms. Amna Irum Co-Supervised by Dr. Qurut-ul-Ain Department of Data Science And Artificial Intelligence National University of Computer and Emerging Sciences Islamabad, Pakistan June, 2026\n",
      "\n",
      "Contents 1 Introduction 11 1.1 Existing Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 1.2 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 1.3 Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 1.4 Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 1.4.1 Module 1: Dataset Pipeline . . . . . . . . . . . . . . . . . . . . 33 1.4.2 Module 2: Animation Pipeline . . . . . . . . . . . . . . . . . . . 44 1.4.3 Module 3: Quiz System . . . . . . . . . . . . . . . . . . . . . . . 44 1.4.4 Module 4: Real-Time QA System . . . . . . . . . . . . . . . . . 44 1.4.5 Module 5: Personalized Dashboard . . . . . . . . . . . . . . . . . 44 1.4.6 Module 6: Classroom . . . . . . . . . . . . . . . . . . . . . . . 55 2 Project Requirements 77 2.1 Use-case/Event Response Table/Storyboarding . . . . . . . . . . . . . . . 77 2.2 Functional Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . 77 2.2.1 Module 1: Dataset Pipeline . . . . . . . . . . . . . . . . . . . . . 77 2.2.2 Module 2: Animation Pipeline . . . . . . . . . . . . . . . . . . . 88 2.2.3 Module 3: Quiz System . . . . . . . . . . . . . . . . . . . . . . . 99 2.2.4 Module 4: Real-Time QA System . . . . . . . . . . . . . . . . . 1100 2.2.5 Module 5: Personalized Dashboard . . . . . . . . . . . . . . . . . 1100 2.2.6 Module 6: Classroom . . . . . . . . . . . . . . . . . . . . . . . . 1111 2.3 Non-Functional Requirements . . . . . . . . . . . . . . . . . . . . . . . 1111 2.3.1 Reliability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1111 2.3.2 Usability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1122 2.3.3 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1133 2.3.4 Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1133 3 System Overview 1155 3.1 Architectural Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1155 3.2 Data Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1177 3.3 Domain Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1199 3.4 Design Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2233 3.4.1 Behavioral and Structural Diagrams . . . . . . . . . . . . . . . . 2233\n",
      "\n",
      "3.4.1.1 Activity Diagram . . . . . . . . . . . . . . . . . . . . . 2233 3.4.1.2 Class Diagram . . . . . . . . . . . . . . . . . . . . . . 2255 3.4.1.3 Sequence Diagram . . . . . . . . . . . . . . . . . . . . 2277 3.4.1.4 DataFlow Diagram . . . . . . . . . . . . . . . . . . . . 3300 4 Implementation and Testing 3333 4.1 Algorithm Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3333 4.1.1 Vector Similarity Search Algorithm . . . . . . . . . . . . . . . . 3344 4.1.2 Dataset Generation Algorithm . . . . . . . . . . . . . . . . . . . 3344 4.1.3 Quiz Generation Algorithm . . . . . . . . . . . . . . . . . . . . . 3355 4.2 External APIs/SDKs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3355 4.2.1 Groq API Integration Details . . . . . . . . . . . . . . . . . . . . 3377 4.3 Testing Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3399 4.3.1 Unit Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3399 4.3.1.1 Test Case 1: Query Validation . . . . . . . . . . . . . . 3399 4.3.1.2 Test Case 2: Vector Similarity Search . . . . . . . . . . 4411 4.3.1.3 Test Case 3: Manim Code Validation . . . . . . . . . . 4433 4.3.1.4 Test Case 4: Solution Validation with SymPy . . . . . . 4455 4.3.2 Integration Testing . . . . . . . . . . . . . . . . . . . . . . . . . 4477 4.3.2.1 End-to-End Animation Generation Test . . . . . . . . . 4477 4.3.2.2 Quiz Generation and Submission Flow Test . . . . . . . 4488 4.3.3 Performance Testing . . . . . . . . . . . . . . . . . . . . . . . . 5500 4.3.3.1 Load Testing Results . . . . . . . . . . . . . . . . . . . 5500 4.3.3.2 Stress Testing . . . . . . . . . . . . . . . . . . . . . . . 5511 4.3.4 Security Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . 5533 4.3.4.1 SQL Injection Testing . . . . . . . . . . . . . . . . . . 5533 4.3.4.2 API Key Security Testing . . . . . . . . . . . . . . . . 5544 4.3.5 Known Issues and Limitations . . . . . . . . . . . . . . . . . . . 5544 A Appendices 5555 A.1 Appendix A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5566 A.1.1 Use Case Diagram example (Rehnuma) . . . . . . . . . . . . . . 5566 A.1.2 Detail Use Case Example . . . . . . . . . . . . . . . . . . . . . . 5577 A.2 Appendix B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5599 A.2.1 Class Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . 5599 A.3 Appendix C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6600 A.3.1 Architecture Pattern Example . . . . . . . . . . . . . . . . . . . . 6600 A.4 Appendix D . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6622 A.4.1 Activity Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . 6622 A.4.2 Sequence Diagram . . . . . . . . . . . . . . . . . . . . . . . . . 6633 A.4.3 Data Flow Diagram . . . . . . . . . . . . . . . . . . . . . . . . . 6655\n",
      "\n",
      "List of Figures 3.1 Architecture Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1177 3.2 Usecase Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2222 3.3 Activity Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2244 3.4 Class Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2266 3.5 Sequence Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2299 3.6 DataFlow Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3322 4.1 Dashboard . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3399 4.2 Dashboard-2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4400 4.3 Solution-Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4411 4.4 Manim-Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4455 4.5 Animation-Calculation . . . . . . . . . . . . . . . . . . . . . . . . . . . 5500 4.6 Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5511 4.7 Testcases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5533 A.1 Use Case Diagram for Rehnuma . . . . . . . . . . . . . . . . . . . . . . 5566 A.2 Detailed Use Case Example of Rehnuma . . . . . . . . . . . . . . . . . . 5588 A.3 Class Diagram for Rehnuma . . . . . . . . . . . . . . . . . . . . . . . . 5599 A.4 Architecture Pattern For Rehnuma . . . . . . . . . . . . . . . . . . . . . 6600 A.5 Activity Diagram For Rehnuma . . . . . . . . . . . . . . . . . . . . . . . 6622 A.6 Sequence Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6644 A.7 Data Flow Diagram for Rehnuma . . . . . . . . . . . . . . . . . . . . . . 6666\n",
      "\n",
      "List of Tables 1.1 Comparison of Existing Solutions . . . . . . . . . . . . . . . . . . . . . 22 4.1 External APIs and SDKs Used in Rehnuma . . . . . . . . . . . . . . . . 3366 4.2 Performance Testing Results . . . . . . . . . . . . . . . . . . . . . . . . 5511\n",
      "\n",
      "Chapter 1 Introduction The purpose of this project proposal is to present “Rehnuma”, an intelligent animated tutoring system designed to assist students in understanding advanced statistical concepts with greater clarity and efficiency. In the current educational environment, students of-ten face significant challenges when dealing with probability and statistics, particularly during their initial semesters where prior exposure is limited. Traditional learning re-sources such as static notes, lengthy textbooks, or unstructured online videos often fail to provide personalized and interactive explanations. Rehnuma bridges this gap by offering a system that dynamically generates animated videos, coupled with explanatory narra-tion, tailored to specific queries raised by students. By integrating large language models (LLMs), retrieval-augmented generation (RAG) pipelines, and Manim animations, the system ensures that learners receive accurate, visual, and concept-based explanations. This approach not only makes abstract concepts easier to grasp but also enhances long-term retention. The proposed system will ultimately create a self-adaptive, accessible, and interactive platform that aligns with modern digital learning trends. ?. 1.1 Existing Solutions Several online learning platforms currently provide mathematics and science education, but they present notable limitations in personalization and real-time interaction. The two leading solutions are: • Khan Academy Offers a large library of pre-recorded video lessons with clear narration, structured topic progression, practice exercises, and limited quiz integration.\n",
      "\n",
      "• Brilliant.org Provides pre-designed interactive lessons, rich quiz integration, problem-solving-focused courses, and supporting text/narration. Personalization is restricted to pre-defined course paths. Table 1.1: Comparison of Existing Solutions System Name System Overview System Limitations Khan Academy • Pre-recorded video expla- • No personalization nations with narration • No support for user-input • Structured courses and queries practice exercises • No real-time Q&A • Limited quiz integration • Pre-recorded content only Brilliant.org • Pre-designed interactive • Limited personalization explanations (only within predefined courses) • Strong quiz integration • No support for arbitrary • Structured, problem-user-input queries solving-focused courses • No real-time Q&A • Narration/supporting text 1.2 Problem Statement Students entering advanced courses in probability and statistics frequently encounter dif-ficulties due to their limited background in conceptual mathematics. These difficulties of-ten lead to surface-level understanding and a lack of problem-solving confidence. While numerous online resources such as YouTube lectures and digital textbooks exist, they re-quire students to spend a considerable amount of time searching for the right content, which is often not aligned with their exact query. Moreover, most of these resources present content in a generic, onesize-fits-all manner that does not adapt to a learner’s spe-cific knowledge gaps. This inefficiency reduces the effectiveness of independent learning, especially for students who require instant clarity. Students may also face cognitive over-load while navigating long lectures for a single concept. The absence of interactive and context-aware tutoring tools contributes to weak conceptual foundations, resulting in poor\n",
      "\n",
      "academic performance. Rehnuma addresses this problem by providing an on-demand in-telligent tutor capable of delivering personalized animated explanations directly based on student queries. By doing so, the system eliminates the inefficiencies of manual content search and ensures that students receive focused, visual, and clear explanations. 1.3 Scope The scope of Rehnuma encompasses the development of a fully functional prototype that demonstrates the generation of animated explanations for queries. The main focus lies in probability and statistics concepts, ensuring that the content generated is accurate, rele-vant, and comprehensible. The system will include functionalities such as query-based animated video generation, quiz generation, real-time QA, personalized dashboard, and a classroom. Scope boundaries include limiting the dataset to curated problems from se-lected textbooks and restricting animation generation to Manim-compatible scripts. The solution will not attempt to replace human instruction but rather supplement it by pro-viding students with an intelligent self-learning platform. This ensures a clear boundary between automated explanations and human-led discussions, making the system a sup-portive tool rather than a replacement. The system will demonstrate the feasibility of integrating LLMs, RAG pipelines, and Manim to create an adaptive educational tool that enhances independent learning, improves conceptual clarity, and promotes confidence in tackling mathematical problems. 1.4 Modules 1.4.1 Module 1: Dataset Pipeline This module is responsible for creating and managing the core dataset required for query-based explanations. It ensures structured storage of problems, solutions, and animation codes in a retrievable format for efficient usage in the system. 1. Generate a dataset using DeepSeek Math from textbook solutions. 2. Store problems with multiple keys (description, code, etc.) in JSON format. 3. Implement ChromaDB for vector storage and retrieval\n",
      "\n",
      "1.4.2 Module 2: Animation Pipeline The animation pipeline generates customized visual explanations based on student queries. It integrates solution generation, reference retrieval, and code rendering to create synchro-nized video and audio explanations. 1. Use DeepSeek Math for solution generation. 2. Retrieve reference problems through RAG. 3. Employ DeepSeek Code for generating Manim-compatible code. 4. Render animations with synced audio explanations using gtts (Python library). 1.4.3 Module 3: Quiz System This module reinforces learning by generating quizzes linked to student queries. It allows students to test their understanding and track progress through structured evaluations. 1. Generate quizzes from user queries using DeepSeek Math. 2. Provide multiple-choice questions (MCQs) with scoring. 3. Integrate with the dashboard for progress tracking. 1.4.4 Module 4: Real-Time QA System The QA system enables instant responses to student doubts during or after lessons. It ensures continuity in the learning process through text-based, real-time interaction. 1. Use DeepSeek Math for real-time responses. 2. Provide answers in text format. 1.4.5 Module 5: Personalized Dashboard This module offers personalized tracking of a student’s progress and performance. It ensures learners receive feedback and insights into their strengths and weaknesses. 1. Display quiz history and performance analytics. 2. Maintain personalized progress records. 3. Provide visual feedback to learners.\n",
      "\n",
      "1.4.6 Module 6: Classroom The classroom module supports collaborative learning by enabling group-based participa-tion. It allows users to share learning experiences and benefit from interactive discussions. 1. Develop a classroom for collaboration. 2. Users will be able to invite other users and watch animations together.\n",
      "\n",
      "Chapter 2 Project Requirements 2.1 Use-case/Event Response Table/Storyboarding Since Rehnuma is an interactive end-user application, the use case approach is most suit-able. The system involves multiple user interactions across different modules, making use case diagrams and detailed use cases the ideal requirement gathering technique. 1. Generate Animated Explanation 2. Take Quiz 3. Ask Real-Time Question 4. View Progress Dashboard 5. Join Classroom Session 6. Create Dataset Entry (Admin) 2.2 Functional Requirements 2.2.1 Module 1: Dataset Pipeline Following are the requirements for module 1: FR1.1:Dataset Generation The system shall allow administrators to input textbook prob-lems and solutions, which will be processed by DeepSeek Math to generate structured dataset entries containing problem descriptions, solutions, and metadata.\n",
      "\n",
      "FR1.2 Code Generation and Validation The system shall use DeepSeek Math to gen-erate Python code from problem-solution pairs and validate the generated code using SymPy and NumPy libraries before storage. FR1.3 Manim Code Generation The system shall automatically generate Manim-compatible animation code and associated metadata for each validated problem-solution pair using Code-Llama. FR1.4 JSON Storage The system shall store all dataset entries in JSON format with multiple searchable keys including problem description, solution steps, Manim code, dif-ficulty level, topic tags, and unique identifiers. FR1.5 Vector Database Integration The system shall implement ChromaDB for vec-tor storage, enabling semantic search and efficient retrieval of similar problems based on query embeddings. FR1.6 Dataset Versioning The system shall maintain version control for dataset entries, allowing administrators to update, modify, or deprecate entries while preserving historical data. 2.2.2 Module 2: Animation Pipeline Following are the requirements for module 2: FR2.1 Query Processing The system shall accept natural language queries from students and process them through prompt engineering to enhance retrieval accuracy. FR2.2 RAG-based Retrieval The system shall retrieve the top-k most relevant reference problems from ChromaDB based on semantic similarity to the user’s query. FR2.3 Solution Generation The system shall generate step-by-step mathematical solu-tions using DeepSeek Math, incorporating context from retrieved reference problems to ensure accuracy and relevance. FR2.4 Animation Code Generation The system shall use Code-Llama to convert the generated solution into Manim-compatible Python code that visualizes the problem-solving\n",
      "\n",
      "process. FR2.5 Video Rendering The system shall render the Manim code into high-quality ani-mated videos (720p minimum) showing step-by-step visualization of the solution. FR2.6 Audio Narration The system shall generate synchronized audio explanations us-ing Google Text-to-Speech (gtts) library, providing clear narration of each solution step alongside the visual animation. FR2.7 Output Delivery The system shall deliver the final animated explanation to the user within 60 seconds of query submission, displaying both video and synchronized audio. 2.2.3 Module 3: Quiz System Following are the requirements for module 3: FR3.1 Quiz Generation The system shall generate topic-specific quizzes based on user queries or selected topics using DeepSeek Math, with 5–10 multiple-choice questions per quiz. FR3.2 Question Difficulty Levels The system shall categorize quiz questions into three difficulty levels: beginner, intermediate, and advanced, allowing students to select appro-priate challenges. FR3.3 Answer Validation The system shall automatically validate student responses, provide immediate feedback, and calculate scores based on correct answers. FR3.4 Detailed Solutions The system shall provide detailed explanations for each quiz question after submission, helping students understand their mistakes. FR3.5 Quiz History The system shall maintain a complete history of all quizzes at-tempted by each student, including timestamps, scores, and topics covered.\n",
      "\n",
      "2.2.4 Module 4: Real-Time QA System Following are the requirements for module 4: FR4.1 Text-based Query Handling The system shall accept text-based questions from students and provide instant responses using DeepSeek Math without generating anima-tions. FR4.2 Contextual Responses The system shall maintain conversation context, allowing follow-up questions and clarifications within the same session. FR4.3 Response Time The system shall provide text-based answers within 5 seconds of query submission for optimal user experience. FR4.4 Query History The system shall store all QA interactions for each student, en-abling review of previous questions and answers. 2.2.5 Module 5: Personalized Dashboard Following are the requirements for module 5: FR5.1 Performance Analytics The system shall display comprehensive analytics includ-ing quiz scores, topics covered, time spent, and improvement trends using visual charts and graphs. FR5.2 Progress Tracking The system shall track and display the student’s learning jour-ney, showing completed topics, pending areas, and recommended next steps. FR5.3 Strengths and Weaknesses Analysis The system shall analyze quiz performance to identify student strengths and weaknesses in different probability and statistics topics. FR5.4 Learning Recommendations The system shall provide personalized topic recom-mendations based on past performance and identified knowledge gaps. FR5.5 Goal Setting The system shall allow students to set learning goals and track progress toward achieving them.\n",
      "\n",
      "2.2.6 Module 6: Classroom Following are the requirements for module 6: FR6.1 Classroom Creation The system shall allow users to create virtual classrooms with unique codes for collaborative learning sessions. FR6.2 User Invitation The system shall enable classroom creators to invite other users via unique classroom codes or direct links. FR6.3 Synchronized Viewing The system shall provide synchronized animation play-back, allowing all classroom participants to watch explanations simultaneously. FR6.4 Real-time Chat The system shall include a text-based chat feature enabling stu-dents to discuss concepts during classroom sessions. FR6.5 Session Recording The system shall optionally record classroom sessions for later review by participants. 2.3 Non-Functional Requirements 2.3.1 Reliability Following are the reliability requirements: REL-1: System Uptime The system shall maintain 80-83% uptime during academic semesters with planned maintenance. REL-2: Failure Recovery In case of animation generation failure, the system shall auto-matically retry within minutes before notifying the user and logging the error for admin-istrator review.\n",
      "\n",
      "REL-3: Data Integrity The system shall implement automatic database backups every 24 hours and maintain backup copies for at least 30 days to ensure data recovery in case of failures. REL-4: Error Handling The system shall gracefully handle API failures from DeepSeek by displaying user-friendly error messages and suggesting alternative actions (e.g., try simpler query, use QA system instead). 2.3.2 Usability Following are the usability requirements: USE-1: Learning Curve New users shall be able to generate their first animated expla-nation within minutes of account creation, with minimal training or documentation. USE-2: Query Simplicity Users shall be able to submit queries using natural language without requiring specific formatting or technical syntax. USE-3: Interface Clarity The system shall use intuitive icons, clear labels, and consis-tent navigation patterns across all modules to minimize cognitive load. USE-4: Error Recovery If a user submits an unclear or ambiguous query, the system shall provide suggestions for query refinement rather than simply returning an error. USE-5: Accessibility The system shall support screen readers and keyboard navigation, ensuring accessibility for users with visual or motor impairments. USE-6: Mobile Responsiveness The web interface shall be fully responsive, providing optimal viewing experience across desktop, tablet, and mobile devices. USE-7: One-Click Access Users shall be able to access their quiz history and dashboard with a single click from any page within the system.\n",
      "\n",
      "2.3.3 Performance Following are the performance requirements: PER-1: Animation Generation Time 95% of animation requests shall be completed within minutes from query submission to video delivery, including solution generation, code creation, and rendering. PER-2: Real-Time QA Response Text-based QA responses shall be delivered within minutes for 99% of queries. PER-3: Quiz Loading Time Quiz pages shall load completely within minutes on stan-dard broadband connections (10 Mbps or higher). PER-4: Concurrent Users The system shall support at least 50 concurrent users gener-ating animations simultaneously without performance degradation. PER-5: Database Query Performance Vector similarity searches in ChromaDB shall return results within 1-2 seconds for 95% of queries. PER-6: Video Streaming Rendered animations shall begin playback within 3 seconds of user request with smooth streaming at 720p resolution. PER-7: Dashboard Loading Personalized dashboard shall load all analytics and visual-izations within minutes. 2.3.4 Security Following are the security requirements: SEC-1: Authentication The system shall implement secure user authentication using industry-standard protocols to prevent unauthorized access. SEC-2: Data Protection User data including quiz results, query history, and personal information shall be encrypted both in transit and at rest.\n",
      "\n",
      "SEC-3: API Key Security External API keys for DeepSeek shall be stored in environ-ment variables or secure vaults, never hardcoded in source code. SEC-4: Session Management User sessions shall automatically expire after 24 hours of inactivity, requiring re-authentication for security. SEC-6: Input Validation All user inputs shall be sanitized and validated to prevent SQL injection, XSS attacks, and other security vulnerabilities. SEC-7: Classroom Privacy Classroom sessions shall be private by default, accessible only to invited participants with valid classroom codes.\n",
      "\n",
      "Chapter 3 System Overview Rehnuma is an intelligent animated tutoring system that revolutionizes probability and statistics education by generating personalized visual explanations on-demand through AI-driven workflows. The system operates through two interconnected pipelines: a Dataset Generation Workflow that creates a comprehensive repository of textbook problems, so-lutions, and Manim animation codes using DeepSeek Math 7B-RL and Claude Sonnet , stored in JSON format and indexed in ChromaDB for semantic retrieval; and a RAG Pro-duction Workflow that processes student queries through prompt engineering, retrieves relevant reference problems, generates step-by-step solutions using DeepSeek Math, con-verts solutions into Manim code via DeepSeek Coder, and renders synchronized video an-imations with audio narration within 60 seconds. Beyond core animation generation, the system includes a Quiz System for knowledge assessment, a Real-Time QA System for instant text-based answers, a Personalized Dashboard for progress tracking and analytics, and a Classroom module for collaborative learning sessions. Built on a layered architec-ture with React.js frontend, FastAPI/Flask backend, integrated AI/ML APIs (DeepSeek Math, DeepSeek Coder, Claude Sonnet), and hybrid data storage (PostgreSQL for rela-tional data, ChromaDB for vector embeddings, JSON for animation metadata), Rehnuma provides students with an adaptive, accessible, and interactive platform that transforms abstract statistical concepts into clear, visual, and engaging learning experiences. 3.1 Architectural Design Rehnuma follows a Layered Architecture combined with the Client–Server Pattern to achieve modularity, scalability, and maintainability. The system is decomposed into four primary layers:\n",
      "\n",
      "1. Presentation Layer (Frontend) Responsibilities: - Handles user interface and user interactions. - Implements responsive web design using React.js. - Manages user input validation and output display. Components: Query Input Interface, Animation Player, Quiz Interface, Dashboard UI, Classroom Interface. 2. Application Layer (Backend Logic) Responsibilities: - Processes business logic and orchestrates workflows. - Implements FastAPI/Flask server for REST API endpoints. - Manages authentication, session handling, and routing. Components: Query Processor, Animation Generator, Quiz Engine, QA Handler, Class-room Manager. 3. AI/ML Layer (Intelligence) Responsibilities: - Integrates external AI models and handles intelligent operations. - Manages API calls to DeepSeek Math, Code Llama-7B, and Lang Chain. - Implements RAG pipeline with prompt engineering. Components: DeepSeek Math, DeepSeek Coder Interface, Prompt Engineer, ChromaDB Manager. 4. Data Layer (Storage) Responsibilities: - Manages persistent data storage and retrieval. - Implements PostgreSQL for relational data (users, quizzes, sessions). - Implements ChromaDB for vector embeddings and semantic search. - Implements JSON file storage for animation metadata. Components: User Database, Quiz Database, Vector Store, Media Storage. Inter-Layer Communication: Presentation ↔ Application: REST API (HTTP/HTTPS) Application ↔ AI/ML: API calls and internal function calls Application ↔ Data: Database queries (SQL, vector search) AI/ML ↔ Data: Vector embedding storage and retrieval\n",
      "\n",
      "Figure 3.1: Architecture Diagram 3.2 Data Design Vector Database (ChromaDB) Collection: rehnuma_problems • Document: Problem description + solution text • Embedding: 768-dimensional vector (generated using Sentence-Transformers) • Metadata: – problem_id – topic – difficulty – source_textbook – manim_code_path – solution_steps\n",
      "\n",
      "Storage Structure: ChromaDB Collection: \"rehnuma_problems\" Embeddings (vectors) Documents (text) Metadata (JSON) problem_id topic difficulty manim_code solution_json File Storage Structure /storage /animations /videos {animation_id}.mp4 /audio {animation_id}.mp3 /datasets problems_dataset.json /logs error_logs.txt api_usage_logs.txt JSON Dataset Format Example { \"problem_id\": \"prob_001\", \"description\": \"Calculate the probability of...\", \"topic\": \"conditional_probability\", \"difficulty\": \"intermediate\", \"solution_steps\": [ \"Step 1: Identify the given information\", \"Step 2: Apply Bayes’ theorem\" ], \"manim_code\": \"class ProbabilityAnimation(Scene):...\", \"metadata\": { \"source\": \"Ross Chapter 3\",\n",
      "\n",
      "\"created_at\": \"2025-01-15\", \"validated\": true } } Data Flow Write Operations: • User generates animation → Store in animations table + video/audio files • Admin creates dataset entry → Store in PostgreSQL + ChromaDB + JSON • User takes quiz → Store in quiz_attempts table Read Operations: • User queries → Retrieve embeddings from ChromaDB → Fetch metadata from JSON • User views dashboard → Aggregate data from quiz_attempts + queries • User joins classroom → Query classroom_participants Data Synchronization: • PostgreSQL IDs map to ChromaDB metadata • JSON files serve as backup/export format • Regular batch jobs ensure data consistency across databases 3.3 Domain Model The domain model for Rehnuma represents the key conceptual classes and their relation-ships within the system. Core Entities: User Attributes: userID, name, email, password, role, registrationDate Relationships: Creates Queries, Takes Quizzes, Joins Classrooms\n",
      "\n",
      "Query Attributes: queryID, queryText, timestamp, userID Relationships: Generates Animation, Retrieves References Animation Attributes: animationID, videoPath, audioPath, duration, generatedDate Relationships: Based on Solution, Uses ManimCode Solution Attributes: solutionID, steps, explanation, difficulty Relationships: Solves Problem, Generated from Query Problem Attributes: problemID, description, topic, difficulty, source Relationships: Has Solution, Stored in Dataset Dataset Attributes: datasetID, totalEntries, lastUpdated Relationships: Contains Problems, Stored in ChromaDB ManimCode Attributes: codeID, pythonCode, metadata, validationStatus Relationships: Generates Animation, Validated by Validator Quiz Attributes: quizID, topic, difficulty, createdDate Relationships: Contains Questions, Taken by User Question Attributes: questionID, text, options, correctAnswer, explanation Relationships: Part of Quiz QuizAttempt Attributes: attemptID, userID, quizID, score, timestamp Relationships: Records Performance Classroom\n",
      "\n",
      "Attributes: classroomID, name, code, createdDate, creatorID Relationships: Has Participants, Contains Sessions Dashboard Attributes: dashboardID, userID, analyticsData Relationships: Displays Performance, Shows Progress Key Relationships: User (1) ↔ () Query Query (1) ↔ (1) Animation Animation (1) ↔ (1) Solution Solution (1) ↔ (1) Problem Dataset (1) ↔ () Problem User (1) ↔ () QuizAttempt Quiz (1) ↔ () Question Classroom (1) ↔ () User (as participants) User (1) ↔ (1) Dashboard\n",
      "\n",
      "Figure 3.2: Usecase Diagram\n",
      "\n",
      "3.4 Design Models 3.4.1 Behavioral and Structural Diagrams 3.4.1.1 Activity Diagram The activity diagram illustrates the workflow for the primary use case: Generate Ani-mated Explanation. Process Flow: Start: User opens application Submit Query: User enters natural language query Validate Input: System checks query validity Decision: Is query valid? No → Display error message → Return to Submit Query Yes → Continue Engineer Prompt: Enhance query for better retrieval Retrieve References: Search ChromaDB for similar problems Generate Solution: Use DeepSeek Math with context Validate Solution: Check mathematical correctness Decision: Is solution valid? No → Regenerate solution (max 3 attempts) → Return to Generate Solution Yes → Continue Generate Manim Code: Use DeepSeek Coder Render Animation: Execute Manim rendering Generate Audio: Create narration using gtts Sync Audio-Video: Combine audio and video Store Result: Save to database Display Animation: Present to user End: User views explanation Parallel Activities: - While rendering animation, generate audio narration (concurrent). - While displaying animation, update dashboard analytics (background).\n",
      "\n",
      "Figure 3.3: Activity Diagram\n",
      "\n",
      "3.4.1.2 Class Diagram The class diagram represents the structural view of the system with all major classes, their attributes, and relationships. Key Design Decisions: - Information Expert Pattern: Classes are responsible for data they own (e.g., Query class validates its own input). - Creator Pattern: Factory classes create complex objects (e.g., AnimationFactory cre-ates Animation objects). - Controller Pattern: Dedicated controller classes handle system events (e.g., QueryCon-troller). - Low Coupling: Minimal dependencies between classes through interfaces. - High Cohesion: Each class has focused, related responsibilities.\n",
      "\n",
      "Figure 3.4: Class Diagram\n",
      "\n",
      "3.4.1.3 Sequence Diagram The sequence diagram illustrates the interaction between the major system components and external actors over time for the Animation Generation use case. It details the message flow, order of operations, and return values exchanged among the entities. *Participants • Cashier (End User) – Initiates the animation generation process by submitting a query. • System (Green Box) – Core Rehnuma system responsible for handling user input, managing workflows, and coordinating AI interactions. • External AI Services (DeepSeek, Code-Llama) – External APIs responsible for mathematical reasoning, code generation, and language understanding. *Sequence Flow Query Submission Phase 1. User enters a query in the user interface. 2. The system receives and records the query string. Query Processing Phase 1. The system validates the query input. 2. Prompt engineering enhances the query for optimal AI processing. 3. ChromaDB is queried to retrieve similar reference problems. Solution Generation Phase 1. DeepSeek Math receives the context and query. 2. It generates a detailed step-by-step mathematical solution. 3. The system validates the generated solution for correctness.\n",
      "\n",
      "Code Generation Phase 1. DeepSeek Coder receives the validated solution. 2. It produces Manim-compatible Python code for animation rendering. Animation Rendering Phase 1. The system executes the Manim rendering engine. 2. Google Text-to-Speech (gTTS) generates narration audio. 3. The video and audio tracks are synchronized. Output Delivery Phase 1. The rendered animation is stored in media storage. 2. Video and audio file paths are returned to the user interface. 3. The completed animation is displayed to the user. *Alternative Paths • Invalid query input → Display error message and prompt user to retry. • No references found → Use default example problems and continue. • Solution generation fails (after three retries) → Show appropriate error message. • Rendering failure → Suggest simplifying the user query. *Performance Metrics • Average time from query submission to animation display: 60 seconds (95th per-centile). • Each phase includes timeout handling for fault tolerance. *Message Types • Synchronous calls (solid arrows): Communication between QueryController and service modules. • Asynchronous operations: Background rendering of animation and audio process-ing. • Return values (dashed arrows): Results and file paths sent back to the user inter-face.\n",
      "\n",
      "Figure 3.5: Sequence Diagram\n",
      "\n",
      "3.4.1.4 DataFlow Diagram The Data Flow Diagram (DFD) shows how data moves through the Rehnuma system from user input to final output. External Entities • User: Submits queries and views animations • Administrator: Creates dataset entries • DeepSeek Math: AI service for solution and code generation • LLM: AI service for Manim code generation Processes Main RAG Flow: 1. Validate Query: Checks user input validity 2. Enhance Query: Applies prompt engineering 3. Retrieve Context: Searches ChromaDB for similar problems 4. Generate Solution: Creates step-by-step solution via DeepSeek Math 5. Validate Solution: Verifies correctness using SymPy/NumPy 6. Generate Code: Converts solution to Manim code via DeepSeek Math 7. Render Video: Executes Manim rendering 8. Generate Audio: Creates narration using TTS 9. Sync Media: Combines video and audio Dataset Flow: 10. Create Dataset: Processes problem-solution pairs, generates code, stores in dataset Data Stores 1. D1 - Users: User credentials and profiles 2. D2 - ChromaDB: Vector embeddings for semantic search 3. D3 - Animations: Rendered video and audio files\n",
      "\n",
      "4. D4 - Dataset: Problems, solutions, and Manim code in JSON Data Flows Primary Flow: User submits query → validated → enhanced → context retrieved → solution generated → validated → code generated → video and audio rendered in parallel → synchronized → returned to user. Dataset Flow: Administrator inputs problem →LLM generate code → stored in dataset → indexed in ChromaDB for future retrieval. Key Feature: Processes 7.0 and 8.0 execute in parallel to optimize performance, then converge at 9.0 for synchronization.\n",
      "\n",
      "Figure 3.6: DataFlow Diagram\n",
      "\n",
      "Chapter 4 Implementation and Testing This chapter describes the implementation details of the Rehnuma system, including al-gorithm design, external API integration, and comprehensive testing strategies. The im-plementation leverages state-of-the-art AI models accessed through Groq API to ensure cost-effective and high-performance solution generation and code synthesis. 4.1 Algorithm Design The core functionality of Rehnuma relies on several key algorithms that orchestrate the animation generation pipeline. This section presents the pseudocode for the main algo-rithms used in the system. The primary algorithm coordinates the entire workflow from user query to final animation output. It implements a retrieval-augmented generation ap-proach with error handling and retry mechanisms. [H] RAG Animation Generation Pipeline [1] userQuery: String, userID: Integer anima-tionPath: String or ErrorMessage: String queryID ← generateUniqueID() logQuery(queryID, userQuery, userID) NOT validateQuery(userQuery) \"Error: Invalid query format\" en-hancedQuery ← promptEngineer(userQuery) queryEmbedding ← generateEmbedding(enhancedQuery) referenceProblems ← chromaDB.similaritySearch(queryEmbedding, k=4) referenceProb-lems is empty referenceProblems ← getDefaultExamples() context ← formatContext(referenceProblems) retryCount ← 0 maxRetries ← 3 retryCount < maxRetries solution ← callMistral7B(enhancedQuery, context) validateSolution(solution) break retryCount ← retryCount + 1 retryCount == maxRetries \"Error: Solution generation failed after 3 attempts\" manimCode ← call-CodeLlama70B(solution) NOT validateManimSyntax(manimCode) \"Error: Invalid Manim code generated\" videoPath ← renderManimVideo(manimCode) audioPath ← generateAu-dioNarration(solution) animationPath ← synchronizeMediaFiles(videoPath, audioPath) saveAnimationMetadata(queryID, animationPath, solution) animationPath\n",
      "\n",
      "4.1.1 Vector Similarity Search Algorithm This algorithm implements semantic search in ChromaDB using HNSW (Hierarchical Navigable Small World) index to retrieve the most relevant reference problems for a given query. [H] Semantic Similarity Search with HNSW [1] query: String, k: Integer topKProblems: List[Problem] queryEmbedding ← generateEmbedding(query) normalizedQuery ← nor-malize(queryEmbedding) similarityScores ← empty list hnsw_index ← chromaDB.getHNSWIndex() each problem in hnsw_index problemEmbedding ← problem.getEmbedding() similarity ← cosineSimilarity(normalizedQuery, problemEmbedding) similarityScores.add((problem, similarity)) sortedProblems ← sort(similarityScores, descending=True) topKProblems ← sortedProblems[0:k] topKProblems Cosine Similarity Calculation: A · B cosine_similarity(A, B) = (4.1) ||A|| × ||B|| For normalized vectors (||A|| = ||B|| = 1): cosine_similarity(A, B) = A · B (4.2) 4.1.2 Dataset Generation Algorithm This algorithm processes textbook problems to create structured dataset entries with val-idated code and metadata, following the pipeline described in the RAG implementation documentation. [H] Dataset Entry Creation with Text Parsing [1] problemDescription: String, solution: String, admin: User datasetEntry: DatasetEntry or ErrorMessage: String entryID ← gen-erateUniqueID() topic ← extractTopicFromText(problemDescription) problemText, solu-tionText ← splitProblemAndSolution(problemDescription) theory ← generateTheoryDe-scription(topic, problemText) pythonCode ← callMistral7B(problemText, solutionText) NOT validateWithSymPy(pythonCode) \"Error: Python code validation failed\" NOT vali-dateWithNumPy(pythonCode) \"Error: Numerical validation failed\" manimCode ← call-CodeLlama70B(solutionText, pythonCode) metadata ← createMetadata(topic, problem-Text) metadata.add(\"difficulty\", classifyDifficulty(problemText)) metadata.add(\"animation_hint\", generateAnimationMetadata(topic)) datasetEntry ← createEntry(entryID, problemText, theory, solutionText, pythonCode, manimCode, metadata) saveToJSONStorage(datasetEntry) embedding ← generateEmbedding(problemText + solutionText) chromaDB.indexEntry(entryID, embedding, metadata) datasetEntry\n",
      "\n",
      "4.1.3 Quiz Generation Algorithm This algorithm generates adaptive quizzes based on user queries and performance history. [H] Adaptive Quiz Generation [1] userQuery: String, userID: Integer, difficulty: String quiz: Quiz relatedProblems ← searchDataset(userQuery) userHistory ← getUserQuizHis-tory(userID) weakTopics ← identifyWeakTopics(userHistory) questionPool ← empty list topic in weakTopics topicProblems ← filterByTopic(relatedProblems, topic) question-Pool.addAll(topicProblems) selectedQuestions ← randomSample(questionPool, count=10) each question in selectedQuestions mcqOptions ← callMistral7B(\"Generate 4 options for: \" + question) explanation ← callMistral7B(\"Explain solution: \" + question) ques-tion.setOptions(mcqOptions) question.setExplanation(explanation) quiz ← createQuiz(selectedQuestions, difficulty) saveQuizToDatabase(quiz) quiz 4.2 External APIs/SDKs The Rehnuma system integrates multiple external APIs and software development kits to achieve its functionality. The following table describes each external dependency, its purpose, and specific endpoints or functions utilized.\n",
      "\n",
      "API and Version Description Purpose Endpoint/Function Groq API (Mistral 7B) Cloud-hosted inference API for Solution genera- /openai/v1/chat/ Mistral 7B model on free tier tion and mathemat- completions ical reasoning Groq API (Code Cloud-hosted inference API for Manim-compatible /openai/v1/chat/ Llama 3.3 70B) Code Llama 3.3 70B on free tier Python code gener- completions ation ChromaDB v0.4.18 Open-source vector database for Semantic search Collection.query(), embeddings and retrieval of Collection.add() reference problems Sentence- Python library for generating Converting text to SentenceTransformer.encode Transformers v2.2.2 sentence embeddings 768-dim vectors for semantic search Manim Community Mathematical animation engine Rendering anima- manim render, Edition v0.18.0 tions from Python Scene.construct() code Google Text-to- Text-to-speech conversion li- Generating audio gTTS.save(), Speech (gTTS) v2.4.0 brary narration for ani- gTTS(text, mations lang) FFmpeg v6.0 Multimedia framework for video Synchronizing ffmpeg -i processing video and audio video.mp4 -i files audio.mp3 SymPy v1.12 Symbolic mathematics library Validating mathe- sympify(), matical expressions simplify(), and equations solve() NumPy v1.24.3 Numerical computing library Validating numeri- numpy.allclose(), cal computations numpy.isclose() FastAPI v0.104.1 Modern web framework for Backend REST @app.post(), building APIs API implementa- @app.get() tion PostgreSQL v15.4 Relational database manage- Storing user data, SQL queries via ment system quizzes, and ani- psycopg2 mation metadata React v18.2.0 JavaScript library for building Frontend user in- Components, UI terface Hooks, State man-agement Table 4.1: External APIs and SDKs Used in Rehnuma\n",
      "\n",
      "4.2.1 Groq API Integration Details Rehnuma leverages Groq’s cloud infrastructure to access Mistral 7B and Code Llama 3.3 70B models on the free tier, significantly reducing computational costs while maintaining high performance. The integration follows these specifications: Authentication: API key-based authentication using bearer token headers = { \"Authorization\": f\"Bearer {GROQ_API_KEY}\", \"Content-Type\": \"application/json\" } Request Format for Mistral 7B (Solution Generation): { \"model\": \"mistral-7b-instruct\", \"messages\": [ { \"role\": \"system\", \"content\": \"You are a mathematics tutor...\" }, { \"role\": \"user\", \"content\": \"Explain Bayes Theorem...\" } ], \"temperature\": 0.7, \"max_tokens\": 2048 } Request Format for Code Llama 3.3 70B (Code Generation): { \"model\": \"llama-3.3-70b-versatile\", \"messages\": [ { \"role\": \"system\", \"content\": \"Generate Manim Python code...\" }, { \"role\": \"user\",\n",
      "\n",
      "\"content\": \"<solution_text>\" } ], \"temperature\": 0.3, \"max_tokens\": 4096 } Rate Limits (Free Tier): • Mistral 7B: 30 requests per minute • Code Llama 3.3 70B: 20 requests per minute • Implemented exponential backoff retry mechanism for rate limit handling\n",
      "\n",
      "Figure 4.1: Dashboard 4.3 Testing Details Comprehensive testing was conducted to ensure system reliability, correctness, and per-formance. This section details unit testing, integration testing, and system testing strate-gies. 4.3.1 Unit Testing Unit tests were written for all critical components to verify individual function correctness in isolation. The following subsections present key unit tests implemented using Python’s pytest framework. 4.3.1.1 Test Case 1: Query Validation Purpose: Verify that the query validation function correctly identifies valid and invalid user inputs. Test Code: import pytest from app.validators import validateQuery def test_valid_query():\n",
      "\n",
      "Figure 4.2: Dashboard-2 valid_query = \"Explain Bayes Theorem with an example\" assert validateQuery(valid_query) == True def test_empty_query(): empty_query = \"\" assert validateQuery(empty_query) == False def test_query_too_long(): long_query = \"a\" * 501 # Exceeds 500 character limit assert validateQuery(long_query) == False def test_query_with_special_chars(): special_query = \"What is P(A|B)?\" assert validateQuery(special_query) == True def test_query_only_whitespace(): whitespace_query = \" \\n\\t \" assert validateQuery(whitespace_query) == False Expected Results: • Valid queries return True • Empty or whitespace-only queries return False\n",
      "\n",
      "Figure 4.3: Solution-Generation • Queries exceeding 500 characters return False • Queries with mathematical symbols are accepted Actual Results: All tests passed successfully. 4.3.1.2 Test Case 2: Vector Similarity Search Purpose: Verify that the ChromaDB semantic search returns relevant problems based on query similarity. Test Code: import pytest from app.database import ChromaDBManager @pytest.fixture def chroma_db(): db = ChromaDBManager()\n",
      "\n",
      "db.add_test_data([ {\"id\": \"1\", \"text\": \"Bayes theorem problem\", \"topic\": \"probability\"}, {\"id\": \"2\", \"text\": \"Normal distribution example\", \"topic\": \"statistics\"}, {\"id\": \"3\", \"text\": \"Conditional probability question\", \"topic\": \"probability\"} ]) return db def test_similarity_search_returns_correct_count(chroma_db): query = \"probability problem\" results = chroma_db.search(query, k=2) assert len(results) == 2 def test_similarity_search_returns_relevant_results(chroma_db): query = \"Bayes theorem\" results = chroma_db.search(query, k=1) assert \"Bayes\" in results[0][\"text\"] def test_similarity_search_with_empty_query(chroma_db): query = \"\" with pytest.raises(ValueError): chroma_db.search(query, k=3) def test_similarity_search_ranking(chroma_db): query = \"conditional probability\" results = chroma_db.search(query, k=3) # Most similar result should be first assert \"Conditional\" in results[0][\"text\"] or \\ \"probability\" in results[0][\"text\"] Expected Results: • Search returns exactly k results when k results exist • Most similar problems ranked first • Empty query raises ValueError • Results contain relevant keywords Actual Results: All tests passed. Average similarity score for relevant results: 0.87/1.0.\n",
      "\n",
      "4.3.1.3 Test Case 3: Manim Code Validation Purpose: Verify that generated Manim code passes syntax validation before rendering. Test Code: import pytest from app.validators import validateManimSyntax def test_valid_manim_code(): valid_code = \"\"\" from manim import * class Example(Scene): def construct(self): text = Text(\"Hello\") self.play(Write(text)) \"\"\" assert validateManimSyntax(valid_code) == True def test_invalid_python_syntax(): invalid_code = \"\"\" from manim import * class Example(Scene) def construct(self) # Missing colons text = Text(\"Hello\") \"\"\" assert validateManimSyntax(invalid_code) == False def test_missing_scene_class(): no_scene = \"\"\" from manim import * def animate(): text = Text(\"Hello\") \"\"\" assert validateManimSyntax(no_scene) == False def test_missing_construct_method(): no_construct = \"\"\" from manim import * class Example(Scene):\n",
      "\n",
      "def render(self): pass \"\"\" assert validateManimSyntax(no_construct) == False def test_valid_code_with_math(): math_code = \"\"\" from manim import * class Example(Scene): def construct(self): formula = MathTex(r\"P(A|B) = \\\\frac{P(B|A)P(A)}{P(B)}\") self.play(Write(formula)) \"\"\" assert validateManimSyntax(math_code) == True Expected Results: • Valid Manim code with proper Scene class returns True • Code with Python syntax errors returns False • Code without Scene class returns False • Code without construct() method returns False Actual Results: All tests passed successfully.\n",
      "\n",
      "Figure 4.4: Manim-Validation 4.3.1.4 Test Case 4: Solution Validation with SymPy Purpose: Verify that mathematical solutions are validated correctly using SymPy. Test Code: import pytest from app.validators import validateSolution def test_correct_probability_calculation(): solution = { \"equation\": \"P(A|B) = P(B|A) * P(A) / P(B)\", \"values\": {\"P(B|A)\": 0.8, \"P(A)\": 0.01, \"P(B)\": 0.0196}, \"result\": 0.408 } assert validateSolution(solution) == True def test_incorrect_calculation(): solution = { \"equation\": \"P(A|B) = P(B|A) * P(A) / P(B)\",\n",
      "\n",
      "\"values\": {\"P(B|A)\": 0.8, \"P(A)\": 0.01, \"P(B)\": 0.0196}, \"result\": 0.5 # Wrong result } assert validateSolution(solution) == False def test_invalid_probability_range(): solution = { \"equation\": \"P(A) = 1.5\", # Probability > 1 \"result\": 1.5 } assert validateSolution(solution) == False def test_algebra_validation(): solution = { \"equation\": \"x^2 - 5x + 6 = 0\", \"solutions\": [2, 3], \"method\": \"factoring\" } assert validateSolution(solution) == True def test_division_by_zero_detection(): solution = { \"equation\": \"y = 1 / 0\", \"result\": \"undefined\" } assert validateSolution(solution) == False Expected Results: • Correct mathematical calculations return True • Incorrect calculations return False • Probabilities outside [0,1] range return False • Division by zero is detected and rejected Actual Results: All tests passed. SymPy successfully validated 98% of test cases.\n",
      "\n",
      "4.3.2 Integration Testing Integration tests verify that multiple components work correctly together. Key integration test scenarios: 4.3.2.1 End-to-End Animation Generation Test Purpose: Verify complete workflow from query to animation output. Test Procedure: 1. Submit test query: \"Explain Bayes Theorem with medical diagnosis example\" 2. Verify query validation passes 3. Verify ChromaDB retrieval returns 3 reference problems 4. Verify Mistral 7B generates solution (via Groq API) 5. Verify SymPy validation passes 6. Verify Code Llama 3.3 70B generates Manim code (via Groq API) 7. Verify Manim rendering produces MP4 file 8. Verify gTTS generates audio file 9. Verify FFmpeg synchronizes media files 10. Verify animation metadata saved to database 11. Measure total execution time Expected Results: • Complete workflow executes without errors • Final animation file size: 5-15 MB • Total execution time: < 90 seconds • Video resolution: 720p (1280x720) • Audio quality: 44.1kHz, 128kbps Actual Results:\n",
      "\n",
      "• All components integrated successfully • Average animation file size: 8.3 MB • Average execution time: 67 seconds (well within target) • Success rate: 94% (56/60 test queries) • Failures primarily due to API rate limits 4.3.2.2 Quiz Generation and Submission Flow Test Purpose: Test complete quiz workflow from generation to grading. Test Code: def test_quiz_workflow(): # Step 1: Generate quiz user_id = create_test_user() quiz = generate_quiz( user_id=user_id, topic=\"conditional_probability\", difficulty=\"intermediate\" ) assert quiz is not None assert len(quiz.questions) == 10 # Step 2: Submit answers answers = { \"q1\": \"A\", \"q2\": \"C\", \"q3\": \"B\", \"q4\": \"D\", \"q5\": \"A\", \"q6\": \"B\", \"q7\": \"C\", \"q8\": \"A\", \"q9\": \"D\", \"q10\": \"B\" } result = submit_quiz_answers(user_id, quiz.id, answers) # Step 3: Verify grading assert result.score is not None assert 0 <= result.score <= 100 assert result.feedback is not None # Step 4: Verify dashboard update dashboard = get_user_dashboard(user_id) assert quiz.id in dashboard.quiz_history\n",
      "\n",
      "assert dashboard.total_quizzes_taken == 1 Expected Results: • Quiz generated with 10 questions • Score calculated correctly (0-100) • Feedback provided for each question • Dashboard updated with quiz history Actual Results: All integration tests passed. Average quiz generation time: 12 seconds.\n",
      "\n",
      "Figure 4.5: Animation-Calculation 4.3.3 Performance Testing Performance tests were conducted to verify system meets non-functional requirements. 4.3.3.1 Load Testing Results Test Configuration: • Tool: Apache JMeter 5.5 • Concurrent users: 50 simultaneous requests • Duration: 30 minutes • Test queries: Mix of simple and complex probability problems Results:\n",
      "\n",
      "Figure 4.6: Solution Metric Target Actual Status Animation generation time (95th %) 90s 82s Pass Real-time QA response time 5s 3.2s Pass Quiz loading time 3s 2.1s Pass Dashboard loading time 5s 4.3s Pass Concurrent user support 100 100 Pass ChromaDB query time (95th %) 500ms 380ms Pass System uptime 99% 99.2% Pass Table 4.2: Performance Testing Results 4.3.3.2 Stress Testing Purpose: Determine system breaking point under extreme load. Test Procedure: • Gradually increase concurrent users from 50 to 250 • Monitor response times and error rates • Identify bottlenecks Results:\n",
      "\n",
      "• System stable up to 150 concurrent users • Performance degradation begins at 175 users • Groq API rate limits hit at 200+ users • Recommendation: Implement request queuing for >150 users\n",
      "\n",
      "Figure 4.7: Testcases 4.3.4 Security Testing 4.3.4.1 SQL Injection Testing Test Code: def test_sql_injection_prevention(): # Attempt SQL injection in query malicious_query = \"’; DROP TABLE users; --\" response = submit_query(malicious_query) # Verify query sanitized assert \"Error: Invalid query\" in response # Verify database intact user_count = count_users_in_database() assert user_count > 0 # Table not dropped Result: All SQL injection attempts successfully blocked by input sanitization.\n",
      "\n",
      "4.3.4.2 API Key Security Testing Test Procedure: 1. Attempt to access Groq API without authentication 2. Check for hardcoded API keys in source code 3. Verify API keys stored in environment variables 4. Test session expiration after 24 hours Results: • No hardcoded API keys found in repository • All API keys properly stored in .env file • Unauthorized API access blocked • Session expiration working correctly 4.3.5 Known Issues and Limitations 1. Groq API Rate Limits: Free tier limits to 30 requests/minute for Mistral 7B. Im-plemented exponential backoff, but high concurrent load may experience delays. 2. Animation Rendering Time: Complex Manim animations with extensive LaTeX formulas occasionally exceed 90-second target (observed in 6% of test cases). 3. ChromaDB Scalability: Performance degrades with >10,000 indexed problems. Plan to implement sharding for production deployment. 4. Audio-Video Sync: Rare desynchronization (< 1% of cases) when audio duration significantly exceeds video duration.\n",
      "\n",
      "Appendix A Appendices A.1 Appendix A A.1.1 Use Case Diagram example (Rehnuma) Figure A.1: Use Case Diagram for Rehnuma\n",
      "\n",
      "A.1.2 Detail Use Case Example\n",
      "\n",
      "Figure A.2: Detailed Use Case Example of Rehnuma\n",
      "\n",
      "A.2 Appendix B A.2.1 Class Diagram Figure A.3: Class Diagram for Rehnuma\n",
      "\n",
      "A.3 Appendix C A.3.1 Architecture Pattern Example Figure A.4: Architecture Pattern For Rehnuma\n",
      "\n",
      "A.4 Appendix D A.4.1 Activity Diagram\n",
      "\n",
      "A.4.2 Sequence Diagram\n",
      "\n",
      "Figure A.6: Sequence Diagram\n",
      "\n",
      "A.4.3 Data Flow Diagram\n",
      "\n",
      "Figure A.7: Data Flow Diagram for Rehnuma\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Clean text extractor from PDF (page by page) for chatbot knowledge base.\n",
    "\n",
    "- Uses pdfplumber's page.extract_text with tuned tolerances\n",
    "- Normalizes whitespace (removes extra spaces / weird line breaks)\n",
    "- Returns a single cleaned text string\n",
    "\"\"\"\n",
    "\n",
    "import pdfplumber\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# <<< CHANGE THIS TO YOUR PDF FILE PATH >>>\n",
    "PDF_PATH = r\"report.pdf\"  # e.g. r\"C:\\Users\\you\\Documents\\sample.pdf\"\n",
    "\n",
    "\n",
    "def normalize_whitespace(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize whitespace for NLP / chatbot use.\n",
    "\n",
    "    - Join lines into paragraphs.\n",
    "    - Remove extra spaces.\n",
    "    - Fix common hyphenation at line breaks: 'pre-\\nrecorded' -> 'pre-recorded'.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # Fix hyphenation at line breaks\n",
    "    text = re.sub(r\"-\\s*\\n\\s*\", \"-\", text)\n",
    "\n",
    "    # Replace remaining newlines within paragraphs with spaces\n",
    "    # but keep double newlines (paragraph breaks)\n",
    "    text = text.replace(\"\\r\", \"\")\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)  # collapse many blank lines to max 1 blank line\n",
    "\n",
    "    # Within a paragraph, replace single newlines with spaces\n",
    "    lines = text.split(\"\\n\\n\")\n",
    "    normalized_paragraphs = []\n",
    "    for block in lines:\n",
    "        # Turn all internal whitespace in the block into single spaces\n",
    "        block = re.sub(r\"\\s+\", \" \", block).strip()\n",
    "        if block:\n",
    "            normalized_paragraphs.append(block)\n",
    "\n",
    "    # Join paragraphs with a double newline so you still have some structure\n",
    "    return \"\\n\\n\".join(normalized_paragraphs)\n",
    "\n",
    "\n",
    "def clean_lines_remove_page_numbers(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove typical standalone page-number lines like '1', '12', 'Page 3', '3 / 10'.\n",
    "    \"\"\"\n",
    "    cleaned_lines = []\n",
    "    for line in text.splitlines():\n",
    "        stripped = line.strip()\n",
    "        if re.fullmatch(r\"\\d{1,3}\", stripped):\n",
    "            continue\n",
    "        if re.fullmatch(r\"Page\\s+\\d{1,3}\", stripped, flags=re.IGNORECASE):\n",
    "            continue\n",
    "        if re.fullmatch(r\"\\d{1,3}\\s*/\\s*\\d{1,3}\", stripped):\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "\n",
    "def extract_clean_text_from_pdf(\n",
    "    pdf_path: str,\n",
    "    header_height_ratio: float = 0.08,\n",
    "    footer_height_ratio: float = 0.08,\n",
    "    x_tolerance: float = 1.0,\n",
    "    y_tolerance: float = 3.0,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Extract cleaned text from a PDF, page by page.\n",
    "\n",
    "    - Crops top/bottom margins to drop headers/footers.\n",
    "    - Uses pdfplumber's text reconstruction with tolerances.\n",
    "    - Cleans page numbers, then normalizes whitespace globally.\n",
    "    \"\"\"\n",
    "    pdf_path = Path(pdf_path)\n",
    "    all_pages_raw = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            width = page.width\n",
    "            height = page.height\n",
    "\n",
    "            top_crop = header_height_ratio * height\n",
    "            bottom_crop = height - footer_height_ratio * height\n",
    "            main_region = page.crop((0, top_crop, width, bottom_crop))\n",
    "\n",
    "            page_text = main_region.extract_text(\n",
    "                x_tolerance=x_tolerance,\n",
    "                y_tolerance=y_tolerance,\n",
    "            ) or \"\"\n",
    "\n",
    "            page_text = clean_lines_remove_page_numbers(page_text)\n",
    "            if page_text.strip():\n",
    "                all_pages_raw.append(page_text)\n",
    "\n",
    "    joined_text = \"\\n\\n\".join(all_pages_raw)\n",
    "    cleaned_text = normalize_whitespace(joined_text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Example usage in a notebook cell\n",
    "clean_text = extract_clean_text_from_pdf(PDF_PATH)\n",
    "print(clean_text)  # preview first 2000 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3b532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d5137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
